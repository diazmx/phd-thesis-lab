{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JN07 - Build a Bipartite Network\n",
    "---\n",
    "In this notebook, we developed the bipartite network from a .csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import igraph as ig\n",
    "import auxiliar_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Global variables\n",
    "### Global variables\n",
    "\n",
    "DATASET = \"TOY\" # AMZ, HC, PM, UN, TOY\n",
    "NODE_TYPE = False\n",
    "\n",
    "PATH_DATASET = auxiliar_path.get_path_dataset(DATASET)\n",
    "PATH_NODETYPE = auxiliar_path.get_path_topbot(NODE_TYPE)\n",
    "\n",
    "GLOBAL_PATH = \"/Users/ddiaz/Documents/code/phd-thesis-lab/\"\n",
    "\n",
    "# File CSV\n",
    "FILENAME = GLOBAL_PATH + \"12-third_year/00-Data/\"+PATH_DATASET+\"/01-DistributionsCSV/\"+DATASET+\"-Rw.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   uname   100 non-null    int64\n",
      " 1   rname   100 non-null    int64\n",
      " 2   ACTION  100 non-null    int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 2.5 KB\n",
      "None\n",
      "\n",
      "|U| = 8\n",
      "|R| = 4\n",
      "|U+R| = 12\n",
      "\n",
      "|L| = 14\n",
      "|L+| = 14\n",
      "|L-| = 0\n",
      "\n",
      "*******************************************\n",
      "** CORRECT FLAG: Same number L = L+ + L- **\n",
      "*******************************************\n"
     ]
    }
   ],
   "source": [
    "### Read CSV\n",
    "\n",
    "df = pd.read_csv(FILENAME)\n",
    "\n",
    "# Remove noisy column\n",
    "df = df.drop(columns=[\"Unnamed: 0\"])\n",
    "print(df.info()) # Info\n",
    "print()\n",
    "\n",
    "# Obtener identificadores únicos por tipo\n",
    "unique_source = sorted(df['uname'].unique())  # Nodos tipo 1\n",
    "unique_target = sorted(df['rname'].unique())  # Nodos tipo 2\n",
    "\n",
    "# Crear nuevo mapeo de IDs\n",
    "source_mapping = {old_id: new_id for new_id, old_id in enumerate(unique_source)}\n",
    "start_target_id = len(unique_source)  # El primer ID del target será el último del source + 1\n",
    "target_mapping = {old_id: new_id for new_id, old_id in enumerate(unique_target, start=start_target_id)}\n",
    "\n",
    "# Aplicar el mapeo al dataframe\n",
    "df_mapped = df.replace({'uname': source_mapping, 'rname': target_mapping})\n",
    "\n",
    "# Contar la frecuencia correcta después del mapeo\n",
    "source_counts = df_mapped['uname'].value_counts().to_dict()\n",
    "target_counts = df_mapped['rname'].value_counts().to_dict()\n",
    "\n",
    "# Fusionar ambas frecuencias.\n",
    "node_frequencies = {node: source_counts.get(node, 0) + target_counts.get(node, 0) for node in range(len(source_mapping) + len(target_mapping))}\n",
    "\n",
    "# Contar la frecuencia de cada arista después del mapeo\n",
    "edge_counts = df_mapped.groupby(['uname', 'rname']).size().to_dict()\n",
    "\n",
    "# Some information about access requests\n",
    "n_user = len(df_mapped.uname.drop_duplicates())\n",
    "n_rscs = len(df_mapped.rname.drop_duplicates())\n",
    "print(f\"|U| = {n_user}\")\n",
    "print(f\"|R| = {n_rscs}\")\n",
    "print(f\"|U+R| = {n_user+n_rscs}\")\n",
    "print()\n",
    "\n",
    "# Possible edges\n",
    "n_acc_res = len(df_mapped.drop_duplicates([\"uname\", \"rname\"]))\n",
    "df_pos = df_mapped[df_mapped.ACTION == 1]\n",
    "n_ar_pos = len(df_pos.drop_duplicates())\n",
    "n_ar_neg = len(df_mapped[df_mapped.ACTION == 0].drop_duplicates())\n",
    "\n",
    "print(f\"|L| = {n_acc_res}\")\n",
    "print(f\"|L+| = {n_ar_pos}\")\n",
    "print(f\"|L-| = {n_ar_neg}\")\n",
    "print()\n",
    "\n",
    "if n_acc_res == n_ar_pos+n_ar_neg:\n",
    "    print(\"*\"*43)\n",
    "    print(\"** CORRECT FLAG: Same number L = L+ + L- **\")\n",
    "    print(\"*\"*43)\n",
    "\n",
    "# To generate a new .CSV file with the clean data\n",
    "filename_csv = GLOBAL_PATH + \"12-third_year/00-Data/\"+PATH_DATASET+\"/01-DistributionsCSV/\"+DATASET+\"-MOD.csv\"\n",
    "df_mapped.to_csv(filename_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IGRAPH U-WT 12 14 -- \n",
      "+ attr: freq (v), id (v), type (v), weight (e)\n",
      "|V| = 12\n",
      "|U| = 8\n",
      "|R| = 4\n",
      "|E| = 14\n",
      "Is bipartite = True\n"
     ]
    }
   ],
   "source": [
    "### Generate bipartite graph\n",
    "\n",
    "# Crear el grafo bipartito en igraph\n",
    "edges = list(edge_counts.keys())  # Lista de aristas sin duplicados\n",
    "g = ig.Graph(edges=edges, directed=False)\n",
    "\n",
    "# Agregar identificador\n",
    "g.vs['id'] = list(range(g.vcount()))\n",
    "\n",
    "# Etiquetar los nodos con su tipo\n",
    "g.vs['type'] = [0] * len(source_mapping) + [1] * len(target_mapping)  # 0 para tipo 1, 1 para tipo 2\n",
    "\n",
    "# Agregar el atributo de frecuencia de los nodos\n",
    "g.vs['freq'] = [node_frequencies[node] for node in range(len(g.vs))]\n",
    "\n",
    "# Agregar el atributo de peso a las aristas\n",
    "g.es['weight'] = [edge_counts[edge] for edge in edges]\n",
    "\n",
    "# Number of nodes\n",
    "print(g.summary())\n",
    "print(f\"|V| = {g.vcount()}\")\n",
    "print(f\"|U| = {len(g.vs.select(type_eq=0))}\")\n",
    "print(f\"|R| = {len(g.vs.select(type_eq=1))}\")\n",
    "print(f\"|E| = {g.ecount()}\")\n",
    "print(f\"Is bipartite = {g.is_bipartite()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[igraph.Vertex(<igraph.Graph object at 0x11a107740>, 0, {'id': 0, 'type': 0, 'freq': 11}),\n",
       " igraph.Vertex(<igraph.Graph object at 0x11a107740>, 1, {'id': 1, 'type': 0, 'freq': 8}),\n",
       " igraph.Vertex(<igraph.Graph object at 0x11a107740>, 2, {'id': 2, 'type': 0, 'freq': 27}),\n",
       " igraph.Vertex(<igraph.Graph object at 0x11a107740>, 3, {'id': 3, 'type': 0, 'freq': 22}),\n",
       " igraph.Vertex(<igraph.Graph object at 0x11a107740>, 4, {'id': 4, 'type': 0, 'freq': 12}),\n",
       " igraph.Vertex(<igraph.Graph object at 0x11a107740>, 5, {'id': 5, 'type': 0, 'freq': 8}),\n",
       " igraph.Vertex(<igraph.Graph object at 0x11a107740>, 6, {'id': 6, 'type': 0, 'freq': 2}),\n",
       " igraph.Vertex(<igraph.Graph object at 0x11a107740>, 7, {'id': 7, 'type': 0, 'freq': 10}),\n",
       " igraph.Vertex(<igraph.Graph object at 0x11a107740>, 8, {'id': 8, 'type': 1, 'freq': 23}),\n",
       " igraph.Vertex(<igraph.Graph object at 0x11a107740>, 9, {'id': 9, 'type': 1, 'freq': 39}),\n",
       " igraph.Vertex(<igraph.Graph object at 0x11a107740>, 10, {'id': 10, 'type': 1, 'freq': 13}),\n",
       " igraph.Vertex(<igraph.Graph object at 0x11a107740>, 11, {'id': 11, 'type': 1, 'freq': 25})]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(g.vs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   uname   100 non-null    int64\n",
      " 1   rname   100 non-null    int64\n",
      " 2   ACTION  100 non-null    int64\n",
      "dtypes: int64(3)\n",
      "memory usage: 2.5 KB\n",
      "None\n",
      "[(0, 11), (1, 8), (2, 27), (3, 22), (4, 12), (5, 8), (6, 2), (7, 10)]\n",
      "[(8, 23), (9, 39), (10, 13), (11, 25)]\n",
      "[11, 3, 5, 7, 20, 2, 10, 5, 5, 4, 8, 8, 2, 10]\n"
     ]
    }
   ],
   "source": [
    "new_df = pd.read_csv(filename_csv)\n",
    "print(new_df.info())\n",
    "\n",
    "print(list(sorted(new_df['uname'].value_counts().to_dict().items())))\n",
    "print(list(sorted(new_df['rname'].value_counts().to_dict().items())))\n",
    "print(list(new_df.groupby(['uname', 'rname']).size().to_dict().values()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11, 3, 5, 7, 20, 2, 10, 5, 5, 4, 8, 8, 2, 10]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.es[\"weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save the graph\n",
    "\n",
    "FILE_GRAPH = GLOBAL_PATH + \"12-third_year/00-Data/\"+PATH_DATASET+\"/02-Graphs/binet-\"+DATASET+\"-Rw.graphml\"\n",
    "g.write_graphml(FILE_GRAPH  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
