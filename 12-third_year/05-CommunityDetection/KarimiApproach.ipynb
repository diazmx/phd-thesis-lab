{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Karimi Proposal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DO NOT CHANGE THIS CODE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pmtools2 as pm\n",
    "import kmodes\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ACTION', 'RESOURCE', 'MGR_ID', 'ROLE_ROLLUP_1', 'ROLE_ROLLUP_2', 'ROLE_DEPTNAME', 'ROLE_TITLE', 'ROLE_FAMILY_DESC', 'ROLE_FAMILY', 'ROLE_CODE']\n",
      "#Entries: 32769\n",
      "#Users: 9561\n",
      "#Resources: 7518\n",
      "\n",
      "---Attributes---\n",
      "Num values ACTION : 2\n",
      "Num values RESOURCE : 7518\n",
      "Num values MGR_ID : 4243\n",
      "Num values ROLE_ROLLUP_1 : 128\n",
      "Num values ROLE_ROLLUP_2 : 177\n",
      "Num values ROLE_DEPTNAME : 449\n",
      "Num values ROLE_TITLE : 343\n",
      "Num values ROLE_FAMILY_DESC : 2358\n",
      "Num values ROLE_FAMILY : 67\n",
      "Num values ROLE_CODE : 343\n",
      "#Filtered resources: 70\n",
      "\n",
      "Num positive entries: 30872\n",
      "Num negative entries: 1897\n",
      "#Resources: 70\n"
     ]
    }
   ],
   "source": [
    "# LOAD DATA\n",
    "#DO NOT CHANGE THIS CODE\n",
    "df_emp_access = pd.read_csv('train.csv')\n",
    "attnames_list = list(df_emp_access.columns)\n",
    "print(attnames_list)\n",
    "#A_III Statistics\n",
    "\n",
    "#DO NOT CHANGE THIS CODE\n",
    "entries = df_emp_access.values.tolist()\n",
    "attidx_to_collcounter = pm.get_entries_freqs(entries)\n",
    "\n",
    "print('#Entries:', len(entries))\n",
    "print('#Users:', len(df_emp_access[attnames_list[2:]].drop_duplicates()))\n",
    "print('#Resources:', len(df_emp_access.RESOURCE.drop_duplicates()))\n",
    "print()\n",
    "\n",
    "print('---Attributes---')\n",
    "for att_idx in range(len(attnames_list)):\n",
    "    print('Num values', attnames_list[att_idx], ':', len(attidx_to_collcounter[att_idx].keys()))\n",
    "num_resources = attnames_list[1]\n",
    "\n",
    "#B_I Filter resources\n",
    "\n",
    "#DO NOT CHANGE THIS CODE\n",
    "n1 = 0\n",
    "n2 = 69\n",
    "num_resources = 7518\n",
    "top_list = df_emp_access['RESOURCE'].value_counts()[:num_resources].index.tolist()\n",
    "#Filter the interval between n1 and n2\n",
    "top_list = top_list[n1:n2+1]\n",
    "print('#Filtered resources:', len(top_list))\n",
    "    \n",
    "print()\n",
    "df_pos_entries = df_emp_access[df_emp_access['ACTION']==1]\n",
    "df_neg_entries = df_emp_access[df_emp_access['ACTION']==0]\n",
    "print('Num positive entries:',len(df_pos_entries))\n",
    "print('Num negative entries:',len(df_neg_entries))\n",
    "\n",
    "#DO NOT CHANGE THIS CODE\n",
    "boolean_series = df_pos_entries.RESOURCE.isin(top_list)\n",
    "df_pos_entries_ = df_pos_entries[boolean_series]\n",
    "boolean_series = df_neg_entries.RESOURCE.isin(top_list)\n",
    "df_neg_entries_ = df_neg_entries[boolean_series]\n",
    "\n",
    "df_pos_entries = df_pos_entries_\n",
    "df_neg_entries = df_neg_entries_\n",
    "\n",
    "pos_entries = df_pos_entries_.values.tolist()\n",
    "neg_entries = df_neg_entries_.values.tolist()\n",
    "\n",
    "print('#Resources:', len(df_pos_entries.RESOURCE.drop_duplicates()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ACTION', 'RESOURCE', 'MGR_ID', 'ROLE_ROLLUP_1', 'ROLE_ROLLUP_2', 'ROLE_DEPTNAME', 'ROLE_TITLE', 'ROLE_FAMILY_DESC', 'ROLE_FAMILY', 'ROLE_CODE']\n",
      "#Entries: 32769\n",
      "#Users: 9561\n",
      "#Resources: 7518\n",
      "\n",
      "---Attributes---\n",
      "Num values ACTION : 2\n",
      "Num values RESOURCE : 7518\n",
      "Num values MGR_ID : 4243\n",
      "Num values ROLE_ROLLUP_1 : 128\n",
      "Num values ROLE_ROLLUP_2 : 177\n",
      "Num values ROLE_DEPTNAME : 449\n",
      "Num values ROLE_TITLE : 343\n",
      "Num values ROLE_FAMILY_DESC : 2358\n",
      "Num values ROLE_FAMILY : 67\n",
      "Num values ROLE_CODE : 343\n",
      "\n",
      "Num positive entries: 30872\n",
      "Num negative entries: 1897\n",
      "#Resources: 7226\n"
     ]
    }
   ],
   "source": [
    "# LOAD DATA\n",
    "#DO NOT CHANGE THIS CODE\n",
    "df_emp_access = pd.read_csv('train.csv')\n",
    "attnames_list = list(df_emp_access.columns)\n",
    "print(attnames_list)\n",
    "#A_III Statistics\n",
    "\n",
    "#DO NOT CHANGE THIS CODE\n",
    "entries = df_emp_access.values.tolist()\n",
    "attidx_to_collcounter = pm.get_entries_freqs(entries)\n",
    "\n",
    "print('#Entries:', len(entries))\n",
    "print('#Users:', len(df_emp_access[attnames_list[2:]].drop_duplicates()))\n",
    "print('#Resources:', len(df_emp_access.RESOURCE.drop_duplicates()))\n",
    "print()\n",
    "\n",
    "print('---Attributes---')\n",
    "for att_idx in range(len(attnames_list)):\n",
    "    print('Num values', attnames_list[att_idx], ':', len(attidx_to_collcounter[att_idx].keys()))\n",
    "num_resources = attnames_list[1]\n",
    "\n",
    "    \n",
    "print()\n",
    "df_pos_entries = df_emp_access[df_emp_access['ACTION']==1]\n",
    "df_neg_entries = df_emp_access[df_emp_access['ACTION']==0]\n",
    "print('Num positive entries:',len(df_pos_entries))\n",
    "print('Num negative entries:',len(df_neg_entries))\n",
    "\n",
    "print('#Resources:', len(df_pos_entries.RESOURCE.drop_duplicates()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing\n",
    "1. Continouos to Categorical Values\n",
    "2. Handle missing values - New value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_data = df_pos_entries[attnames_list[2:]].drop_duplicates()\n",
    "# print('Drop duplicates:', len(df_data))\n",
    "\n",
    "# pos_entries = df_data.values.tolist()\n",
    "pos_entries = df_pos_entries.values.tolist()\n",
    "neg_entries = df_neg_entries.values.tolist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection of Learning Algorithm\n",
    "1. K-modes algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready!\n"
     ]
    }
   ],
   "source": [
    "###Select the number of clusters###\n",
    "num_clusters = 15\n",
    "\n",
    "#DO NOT CHANGE THIS CODE\n",
    "# seed = 29\n",
    "\n",
    "#Compute centroids and labels\n",
    "# num_init = 5\n",
    "centroids = []\n",
    "kmodes_huang = kmodes.KModes(n_clusters=num_clusters, init='Huang', verbose=0)\n",
    "cluster_labels = kmodes_huang.fit_predict(df_pos_entries)\n",
    "centroids = kmodes_huang.cluster_centroids_\n",
    "\n",
    "print('Ready!')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/tesis_env/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_pos_entries[\"cls\"] = cluster_labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter tuning\n",
    "1. Number of clusters (Silhouette Method)\n",
    "2. Cluster initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy Rules Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq(value, attribute, dataplace):\n",
    "    \"\"\"\n",
    "    Calculate the frequency of the value in the dataplace.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    value : int\n",
    "        Value to compute its frequency.\n",
    "\n",
    "    attribute : string\n",
    "        Name of the attribute.\n",
    "\n",
    "    dataplace : DataFrame pandas\n",
    "        Data to search.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float [0-1]\n",
    "        Returns the value of frequency of the value in the data.\n",
    "    \"\"\"\n",
    "    value_freq = dataplace[dataplace[attribute] == value].drop_duplicates()\n",
    "    return len(value_freq) / len(dataplace)\n",
    "\n",
    "def freq_rels(attrA, attrB, dataplace):\n",
    "    \"\"\"\n",
    "    Compute the frequency of the attribute relation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    attrA : string\n",
    "        Name of the attribute A to compare.\n",
    "    attrB : string\n",
    "        Name of the attribute B to compare.\n",
    "    dataplace : DataFrame pandas\n",
    "        Data to search.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float [0-1]\n",
    "        Returns the value of frequency of the range of values in the data.\n",
    "    \"\"\"\n",
    "    # Get the range of values of attribute A.\n",
    "    range_val_A = set(dataplace[attrA].values.tolist())\n",
    "\n",
    "    # Get the range of values of attribute B.\n",
    "    range_val_B = set(dataplace[attrB].values.tolist())\n",
    "\n",
    "    # Check if the len\n",
    "    if len(range_val_A) == len(range_val_B):\n",
    "        # Compute the intersection\n",
    "        inter_A_B = range_val_A.intersection(range_val_B)\n",
    "        if len(inter_A_B) == len(range_val_A):\n",
    "            boolean_series = dataplace[attrA].isin(inter_A_B)\n",
    "            frac_log = dataplace[boolean_series]\n",
    "            return len(frac_log) / len(dataplace) # Return the fraction\n",
    "        return 0\n",
    "    else:\n",
    "        return 0    \n",
    "\n",
    "def extract_attributes_filters(C_i, A, L, posThr, negThr):\n",
    "    \"\"\"\n",
    "    Effective attribute extraction algorithm. Generate a rule for each cluster.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    C_i : DataFrame pandas\n",
    "        Access request in the Cluster i.\n",
    "\n",
    "    A : List\n",
    "        List of attributes.\n",
    "\n",
    "    V : List\n",
    "        Values of attributes.\n",
    "\n",
    "    L : DataFrame\n",
    "        Complete Access Log.\n",
    "\n",
    "    PosThr : float\n",
    "        Positive Threshold to the effective positive attribute.\n",
    "\n",
    "    NegThr : float\n",
    "        Negative Threshold to the effective negative attribute.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        Returns the rule with the effective attributes for the cluster i.\n",
    "    \"\"\"\n",
    "    filter_to_ret = [] # Rule\n",
    "    for a in A:        \n",
    "        a_values = C_i[a].drop_duplicates().tolist()        \n",
    "        for v in a_values:\n",
    "            if freq(v, a, C_i) - freq(v, a, L) > posThr:\n",
    "                if not [a, v] in filter_to_ret:\n",
    "                    filter_to_ret.append([a, v])\n",
    "            if freq(v, a, L) - freq(v, a, C_i) > negThr:\n",
    "                if not [a, -1*v] in filter_to_ret:\n",
    "                    filter_to_ret.append([a, v*-1])\n",
    "    return filter_to_ret\n",
    "\n",
    "def extract_relations(C_i, A, L, posThr, negThr):\n",
    "    \"\"\"\n",
    "    Extract the effective relation. For each cluster.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    C_i : DataFrame pandas\n",
    "        Access request in the Cluster i.\n",
    "\n",
    "    A : List\n",
    "        List of attributes.\n",
    "\n",
    "    L : DataFrame\n",
    "        Complete Access Log.\n",
    "\n",
    "    posThr : float\n",
    "        Positive Threshold to the effective positive relation.\n",
    "\n",
    "    negThr : float\n",
    "        Negative Threshold to the effective negative relation.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        Returns the rule with the effective relation for the cluster i.\n",
    "    \"\"\"\n",
    "    relation_to_ret = []\n",
    "    for a in A:\n",
    "        for b in A:\n",
    "            if a != b:\n",
    "                if freq_rels(a, b, C_i) - freq_rels(a, b, L) > posThr:\n",
    "                    if not [a, b] in relation_to_ret:\n",
    "                        relation_to_ret.append([a, b])\n",
    "                if freq_rels(a, b, L) - freq_rels(a, b, C_i) > negThr:\n",
    "                    if not [a, '!'+b] in relation_to_ret:                        \n",
    "                        relation_to_ret.append([a, '!'+b])\n",
    "                    #print()\n",
    "\n",
    "def rule_inference(data_, pos_attr_thr, \n",
    "    neg_attr_thr, pos_rel_thr, neg_rel_thr):\n",
    "    rule_list = [] # All rules\n",
    "    n_cluster = len(data_[\"cls\"].drop_duplicates()) # N clusters\n",
    "    attrs = data_.columns[:-1] # Name of the columns\n",
    "\n",
    "    for C_i in range(n_cluster):\n",
    "        #print(C_i)\n",
    "        rule_i = []\n",
    "        data_cluster = data_[data_[\"cls\"] == C_i]\n",
    "        \n",
    "        # Effective attributes\n",
    "        attr_filters = extract_attributes_filters(data_cluster, attrs, data_, \n",
    "            pos_attr_thr, neg_attr_thr)    \n",
    "        rule_i.append(attr_filters)        \n",
    "\n",
    "        # Relations\n",
    "        attr_relation = extract_relations(data_cluster, attrs, data_, \n",
    "            pos_rel_thr, neg_rel_thr)\n",
    "        rule_i.append(attr_relation)\n",
    "        #print(rule_i)\n",
    "\n",
    "        rule_list.append([C_i, rule_i])    \n",
    "\n",
    "    return rule_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RESOURCE', 'MGR_ID', 'ROLE_ROLLUP_1', 'ROLE_ROLLUP_2', 'ROLE_DEPTNAME',\n",
       "       'ROLE_TITLE', 'ROLE_FAMILY_DESC', 'ROLE_FAMILY', 'ROLE_CODE', 'cls'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df_pos_entries[df_pos_entries.columns[1:]]\n",
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_attr_thr = 0.3\n",
    "neg_attr_thr = 0.2\n",
    "pos_rel_thr = 0.3\n",
    "neg_rel_thr = 0.2\n",
    "test = rule_inference(df_test, pos_attr_thr, neg_attr_thr, pos_rel_thr, neg_attr_thr)\n",
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_rules = []\n",
    "for rule in test:\n",
    "    only_rules.append(rule[1][0])\n",
    "len(only_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Compute how many rules has a lenght equal to 1.\n",
    "for idx, rule in enumerate(only_rules):\n",
    "    if len(rule) < 2:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "del only_rules[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_neg  = []\n",
    "for i,row in df_pos_entries.iterrows():\n",
    "    \n",
    "    # Evaluación\n",
    "    denies_count = 0    \n",
    "    for rule in only_rules:                                      \n",
    "        # En esta parte se evalua la regla completa\n",
    "        res = True\n",
    "        \n",
    "        #for idx_r, attr_val in enumerate(rule):\n",
    "        for attr_val in rule:            \n",
    "            if attr_val[1] < 0:\n",
    "                if row[attr_val[0]] == attr_val[1]*-1:\n",
    "                    res = False\n",
    "                    break\n",
    "            else:\n",
    "                if row[attr_val[0]] != attr_val[1]:\n",
    "                    res = False\n",
    "                    break\n",
    "        if res == False:\n",
    "            denies_count += 1\n",
    "    \n",
    "    if denies_count == len(only_rules):\n",
    "        false_neg.append(row)\n",
    "        #print(\"FP-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa FN: 43.55\n",
      "FN:  3999  de  9182\n"
     ]
    }
   ],
   "source": [
    "FN = len(false_neg)\n",
    "print(\"Tasa FN: {:.2f}\".format((FN/ len(df_pos_entries))*100))\n",
    "print(\"FN: \", FN, \" de \", len(df_pos_entries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_pos  = []\n",
    "for i,row in df_neg_entries.iterrows():\n",
    "    # Evaluación\n",
    "    denies_count = 0\n",
    "    temp_rules_n = 0\n",
    "    for rule in only_rules:                                      \n",
    "        # En esta parte se evalua la regla completa\n",
    "        res = True                        \n",
    "        for attr_val in rule:\n",
    "            if attr_val[1] < 0:\n",
    "                if row[attr_val[0]] == attr_val[1]*-1:\n",
    "                    res = False\n",
    "                    break\n",
    "            else:\n",
    "                if row[attr_val[0]] != attr_val[1]:\n",
    "                    res = False\n",
    "                    break\n",
    "        if res == False:\n",
    "            denies_count += 1                                \n",
    "    #print(\"XXX-\", denies_count, temp_rules_n, res)\n",
    "    if denies_count < len(only_rules):\n",
    "        false_pos.append(row)\n",
    "        #print(\"FP-2\")    \n",
    "    #else:\n",
    "    #    print(\"ENtra PAPA\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa FP: 56.28\n",
      "FN:  269  de  478\n"
     ]
    }
   ],
   "source": [
    "FP = len(false_pos)\n",
    "print(\"Tasa FP: {:.2f}\".format((FP/ len(df_neg_entries))*100))\n",
    "print(\"FN: \", FP, \" de \", len(df_neg_entries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FN: 3999  - 43.55\n",
      "FP: 269  - 56.28\n",
      "Precision: 0.9506603081438004\n",
      "Recall: 0.5644739708124592\n",
      "F-score 0.7083504168375017\n",
      "# Rules: 14\n",
      "WSC: 53\n"
     ]
    }
   ],
   "source": [
    "\n",
    "TP = len(df_pos_entries) - FN\n",
    "#TP = 50 - FN\n",
    "TN = len(df_neg_entries) - FP\n",
    "#TN = 50 - FP\n",
    "\n",
    "precision = TP / (TP + FP)\n",
    "\n",
    "recall = TP / (TP + FN)\n",
    "\n",
    "fscore = 2*(precision*recall)/(precision+recall)\n",
    "\n",
    "print(\"FN:\", FN, \" - {:.2f}\".format((FN/len(df_pos_entries))*100))\n",
    "#print(\"FN:\", FN, \" - {:.2f}\".format((FN/50)*100))\n",
    "print(\"FP:\", FP, \" - {:.2f}\".format((FP/len(df_neg_entries))*100))\n",
    "#print(\"FP:\", FP, \" - {:.2f}\".format((FP/50)*100))\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F-score\", fscore)\n",
    "\n",
    "def compute_wsc(policy):\n",
    "    return sum([len(rule) for rule in policy])\n",
    "\n",
    "print(\"# Rules:\", len(only_rules))\n",
    "print(\"WSC:\", compute_wsc(only_rules))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy Enhancement\n",
    "1. Rule Pruning\n",
    "2. Policy Refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_rule_to_str(rule):\n",
    "    rule_str = []\n",
    "    #print(rule)\n",
    "    for item in rule:\n",
    "        rule_str.append(item[0]+'*'+str(item[1]))\n",
    "    return set(rule_str)\n",
    "\n",
    "def convert_set_to_list(rule):\n",
    "    rule_list = []    \n",
    "    for item in rule:\n",
    "        rule_list.append([item.split('*')[0], int(item.split('*')[1])])\n",
    "    return rule_list\n",
    "\n",
    "def jaccard_similarity(rule_i, rule_j):\n",
    "\n",
    "    #transofrm data\n",
    "    rule_i_str = convert_rule_to_str(rule_i)\n",
    "    rule_j_str = convert_rule_to_str(rule_j)\n",
    "\n",
    "    intersection = len(list(set(rule_i_str).intersection(rule_j_str)))\n",
    "    union = len(list(set(rule_i_str).union(rule_j_str)))\n",
    "    return float( intersection / union ) \n",
    "\n",
    "def get_similar_rules(rule_i, all_rules):\n",
    "    similar_rules = []\n",
    "    for rule_j in all_rules:\n",
    "        # Jaccard similarity\n",
    "        jaccard_sim = jaccard_similarity(rule_i, rule_j)\n",
    "        if jaccard_sim > 0.5:\n",
    "            similar_rules.append(rule_j)\n",
    "\n",
    "    return similar_rules\n",
    "\n",
    "def fn_refine_policy(fn_rules, all_rules):\n",
    "    new_rules = all_rules\n",
    "    for rule in fn_rules:\n",
    "        \n",
    "        similar_rules = get_similar_rules(rule, all_rules)\n",
    "\n",
    "        if len(similar_rules) == 0:\n",
    "            new_rules.append(rule)\n",
    "        else:\n",
    "            for sim_rule in similar_rules:\n",
    "                rule_str = convert_rule_to_str(rule)\n",
    "                rule_str_sim = convert_rule_to_str(sim_rule)\n",
    "\n",
    "                new_filter = rule_str_sim.difference((rule_str_sim.difference(rule_str)))\n",
    "                print(new_filter)\n",
    "                new_list_filter = convert_set_to_list(new_filter)\n",
    "                idx_to_del = new_rules.index(sim_rule)\n",
    "                del new_rules[idx_to_del]\n",
    "                new_rules.append(new_list_filter)\n",
    "    \n",
    "    return new_rules\n",
    "                \n",
    "\n",
    "def fp_refine_policy(fp_rules, all_rules):\n",
    "    new_rules = all_rules\n",
    "    for rule in fp_rules:\n",
    "        \n",
    "        similar_rules = get_similar_rules(rule, all_rules)\n",
    "\n",
    "        if len(similar_rules) != 0:                    \n",
    "            for sim_rule in similar_rules:\n",
    "                rule_str = convert_rule_to_str(rule)\n",
    "                rule_str_sim = convert_rule_to_str(sim_rule)\n",
    "\n",
    "                new_filter = rule_str_sim.difference((rule_str_sim.difference(rule_str)))\n",
    "                new_list_filter = convert_set_to_list(new_filter)\n",
    "                idx_to_del = new_rules.index(sim_rule)\n",
    "                del new_rules[idx_to_del]\n",
    "                new_rules.append(new_list_filter)\n",
    "    \n",
    "    return new_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_neg = pd.DataFrame(false_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready!\n"
     ]
    }
   ],
   "source": [
    "###Select the number of clusters###\n",
    "num_clusters = 5\n",
    "\n",
    "#DO NOT CHANGE THIS CODE\n",
    "# seed = 29\n",
    "\n",
    "#Compute centroids and labels\n",
    "# num_init = 5\n",
    "centroids = []\n",
    "kmodes_huang = kmodes.KModes(n_clusters=num_clusters, init='Huang', verbose=0)\n",
    "cluster_labels = kmodes_huang.fit_predict(false_neg)\n",
    "centroids = kmodes_huang.cluster_centroids_\n",
    "\n",
    "print('Ready!')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_neg[\"cls\"] = cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_2 = false_neg[false_neg.columns[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_attr_thr = 0.3\n",
    "neg_attr_thr = 0.2\n",
    "pos_rel_thr = 0.3\n",
    "neg_rel_thr = 0.2\n",
    "test = rule_inference(df_test_2, pos_attr_thr, neg_attr_thr, pos_rel_thr, neg_attr_thr)\n",
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_rules_2 = []\n",
    "for rule in test:\n",
    "    only_rules_2.append(rule[1][0])\n",
    "len(only_rules_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_rules_2 = []\n",
    "for rule in test:\n",
    "    only_rules_2.append(rule[1][0])\n",
    "len(only_rules_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute how many rules has a lenght equal to 1.\n",
    "for idx, rule in enumerate(only_rules):\n",
    "    if len(rule) < 2:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "del only_rules[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ROLE_TITLE*118568', 'ROLE_CODE*117880', 'ROLE_FAMILY*19721', 'ROLE_CODE*118570', 'ROLE_TITLE*117879', 'ROLE_DEPTNAME*117878'}\n",
      "{'ROLE_ROLLUP_2*118327', 'ROLE_FAMILY*118453', 'ROLE_FAMILY*-290919'}\n",
      "{'ROLE_FAMILY*-290919', 'ROLE_FAMILY*118398', 'ROLE_ROLLUP_2*118343'}\n",
      "{'ROLE_ROLLUP_1*-117961', 'ROLE_FAMILY*270488', 'ROLE_DEPTNAME*118042', 'ROLE_TITLE*118043', 'ROLE_CODE*118046'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_rules = fn_refine_policy(only_rules_2, only_rules)\n",
    "len(new_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa FN: 38.79\n",
      "FN:  3562  de  9182\n"
     ]
    }
   ],
   "source": [
    "false_neg  = []\n",
    "for i,row in df_pos_entries.iterrows():\n",
    "    \n",
    "    # Evaluación\n",
    "    denies_count = 0    \n",
    "    for rule in only_rules:                                      \n",
    "        # En esta parte se evalua la regla completa\n",
    "        res = True\n",
    "        \n",
    "        #for idx_r, attr_val in enumerate(rule):\n",
    "        for attr_val in rule:            \n",
    "            if attr_val[1] < 0:\n",
    "                if row[attr_val[0]] == attr_val[1]*-1:\n",
    "                    res = False\n",
    "                    break\n",
    "            else:\n",
    "                if row[attr_val[0]] != attr_val[1]:\n",
    "                    res = False\n",
    "                    break\n",
    "        if res == False:\n",
    "            denies_count += 1\n",
    "    \n",
    "    if denies_count == len(only_rules):\n",
    "        false_neg.append(row)\n",
    "        #print(\"FP-2\")\n",
    "\n",
    "FN = len(false_neg)\n",
    "print(\"Tasa FN: {:.2f}\".format((FN/ len(df_pos_entries))*100))\n",
    "print(\"FN: \", FN, \" de \", len(df_pos_entries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa FP: 57.53\n",
      "FN:  275  de  478\n"
     ]
    }
   ],
   "source": [
    "false_pos  = []\n",
    "for i,row in df_neg_entries.iterrows():\n",
    "    # Evaluación\n",
    "    denies_count = 0\n",
    "    temp_rules_n = 0\n",
    "    for rule in only_rules:                                      \n",
    "        # En esta parte se evalua la regla completa\n",
    "        res = True                        \n",
    "        for attr_val in rule:\n",
    "            if attr_val[1] < 0:\n",
    "                if row[attr_val[0]] == attr_val[1]*-1:\n",
    "                    res = False\n",
    "                    break\n",
    "            else:\n",
    "                if row[attr_val[0]] != attr_val[1]:\n",
    "                    res = False\n",
    "                    break\n",
    "        if res == False:\n",
    "            denies_count += 1                                \n",
    "    #print(\"XXX-\", denies_count, temp_rules_n, res)\n",
    "    if denies_count < len(only_rules):\n",
    "        false_pos.append(row)\n",
    "        #print(\"FP-2\")    \n",
    "    #else:\n",
    "    #    print(\"ENtra PAPA\")\n",
    "FP = len(false_pos)\n",
    "print(\"Tasa FP: {:.2f}\".format((FP/ len(df_neg_entries))*100))\n",
    "print(\"FN: \", FP, \" de \", len(df_neg_entries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FN: 3562  - 38.79\n",
      "FP: 275  - 57.53\n",
      "Precision: 0.9533502968617472\n",
      "Recall: 0.61206708778044\n",
      "F-score 0.7455064004775486\n",
      "# Rules: 17\n",
      "WSC: 65\n"
     ]
    }
   ],
   "source": [
    "TP = len(df_pos_entries) - FN\n",
    "#TP = 50 - FN\n",
    "TN = len(df_neg_entries) - FP\n",
    "#TN = 50 - FP\n",
    "\n",
    "precision = TP / (TP + FP)\n",
    "\n",
    "recall = TP / (TP + FN)\n",
    "\n",
    "fscore = 2*(precision*recall)/(precision+recall)\n",
    "\n",
    "print(\"FN:\", FN, \" - {:.2f}\".format((FN/len(df_pos_entries))*100))\n",
    "#print(\"FN:\", FN, \" - {:.2f}\".format((FN/50)*100))\n",
    "print(\"FP:\", FP, \" - {:.2f}\".format((FP/len(df_neg_entries))*100))\n",
    "#print(\"FP:\", FP, \" - {:.2f}\".format((FP/50)*100))\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F-score\", fscore)\n",
    "\n",
    "def compute_wsc(policy):\n",
    "    return sum([len(rule) for rule in policy])\n",
    "\n",
    "print(\"# Rules:\", len(only_rules))\n",
    "print(\"WSC:\", compute_wsc(only_rules))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_neg = pd.DataFrame(false_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready!\n"
     ]
    }
   ],
   "source": [
    "###Select the number of clusters###\n",
    "num_clusters = 5\n",
    "\n",
    "#DO NOT CHANGE THIS CODE\n",
    "# seed = 29\n",
    "\n",
    "#Compute centroids and labels\n",
    "# num_init = 5\n",
    "centroids = []\n",
    "kmodes_huang = kmodes.KModes(n_clusters=num_clusters, init='Huang', verbose=0)\n",
    "cluster_labels = kmodes_huang.fit_predict(false_neg)\n",
    "centroids = kmodes_huang.cluster_centroids_\n",
    "\n",
    "print('Ready!')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_neg[\"cls\"] = cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_2 = false_neg[false_neg.columns[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_attr_thr = 0.3\n",
    "neg_attr_thr = 0.2\n",
    "pos_rel_thr = 0.3\n",
    "neg_rel_thr = 0.2\n",
    "test = rule_inference(df_test_2, pos_attr_thr, neg_attr_thr, pos_rel_thr, neg_attr_thr)\n",
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#only_rules = []\n",
    "for rule in test:\n",
    "    only_rules.append(rule[1][0])\n",
    "len(only_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute how many rules has a lenght equal to 1.\n",
    "for idx, rule in enumerate(only_rules):\n",
    "    if len(rule) == 1:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "del only_rules[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa FN: 0.00\n",
      "FN:  0  de  30872\n"
     ]
    }
   ],
   "source": [
    "false_neg  = []\n",
    "for i,row in df_pos_entries.iterrows():\n",
    "    \n",
    "    # Evaluación\n",
    "    denies_count = 0    \n",
    "    for rule in only_rules:                                      \n",
    "        # En esta parte se evalua la regla completa\n",
    "        res = True\n",
    "        \n",
    "        #for idx_r, attr_val in enumerate(rule):\n",
    "        for attr_val in rule:            \n",
    "            if attr_val[1] < 0:\n",
    "                if row[attr_val[0]] == attr_val[1]*-1:\n",
    "                    res = False\n",
    "                    break\n",
    "            else:\n",
    "                if row[attr_val[0]] != attr_val[1]:\n",
    "                    res = False\n",
    "                    break\n",
    "        if res == False:\n",
    "            denies_count += 1\n",
    "    \n",
    "    if denies_count == len(only_rules):\n",
    "        false_neg.append(row)\n",
    "        #print(\"FP-2\")\n",
    "\n",
    "FN = len(false_neg)\n",
    "print(\"Tasa FN: {:.2f}\".format((FN/ len(df_pos_entries))*100))\n",
    "print(\"FN: \", FN, \" de \", len(df_pos_entries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa FP: 100.00\n",
      "FN:  1897  de  1897\n"
     ]
    }
   ],
   "source": [
    "false_pos  = []\n",
    "for i,row in df_neg_entries.iterrows():\n",
    "    # Evaluación\n",
    "    denies_count = 0\n",
    "    temp_rules_n = 0\n",
    "    for rule in only_rules:                                      \n",
    "        # En esta parte se evalua la regla completa\n",
    "        res = True                        \n",
    "        for attr_val in rule:\n",
    "            if attr_val[1] < 0:\n",
    "                if row[attr_val[0]] == attr_val[1]*-1:\n",
    "                    res = False\n",
    "                    break\n",
    "            else:\n",
    "                if row[attr_val[0]] != attr_val[1]:\n",
    "                    res = False\n",
    "                    break\n",
    "        if res == False:\n",
    "            denies_count += 1                                \n",
    "    #print(\"XXX-\", denies_count, temp_rules_n, res)\n",
    "    if denies_count < len(only_rules):\n",
    "        false_pos.append(row)\n",
    "        #print(\"FP-2\")    \n",
    "    #else:\n",
    "    #    print(\"ENtra PAPA\")\n",
    "FP = len(false_pos)\n",
    "print(\"Tasa FP: {:.2f}\".format((FP/ len(df_neg_entries))*100))\n",
    "print(\"FN: \", FP, \" de \", len(df_neg_entries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FN: 0  - 0.00\n",
      "FP: 1897  - 100.00\n",
      "Precision: 0.9421099209618847\n",
      "Recall: 1.0\n",
      "F-score 0.9701921717132037\n",
      "# Rules: 24\n",
      "WSC: 92\n"
     ]
    }
   ],
   "source": [
    "TP = len(df_pos_entries) - FN\n",
    "#TP = 50 - FN\n",
    "TN = len(df_neg_entries) - FP\n",
    "#TN = 50 - FP\n",
    "\n",
    "precision = TP / (TP + FP)\n",
    "\n",
    "recall = TP / (TP + FN)\n",
    "\n",
    "fscore = 2*(precision*recall)/(precision+recall)\n",
    "\n",
    "print(\"FN:\", FN, \" - {:.2f}\".format((FN/len(df_pos_entries))*100))\n",
    "#print(\"FN:\", FN, \" - {:.2f}\".format((FN/50)*100))\n",
    "print(\"FP:\", FP, \" - {:.2f}\".format((FP/len(df_neg_entries))*100))\n",
    "#print(\"FP:\", FP, \" - {:.2f}\".format((FP/50)*100))\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F-score\", fscore)\n",
    "\n",
    "def compute_wsc(policy):\n",
    "    return sum([len(rule) for rule in policy])\n",
    "\n",
    "print(\"# Rules:\", len(only_rules))\n",
    "print(\"WSC:\", compute_wsc(only_rules))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13 (default, Mar 29 2022, 02:18:16) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "deec884ae07beaa7e970d39d84b9343805b80aeba4e343861fb4097b62dc7004"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
