{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 HC Resource Threshold\n",
    "-------------\n",
    "In this notebook, I'll analyze the number of access requests to all resources.\n",
    "The goal is identify what is the minimun of access requests that each resource\n",
    "must to have to consider it important.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import igraph as ig\n",
    "import networkx as nx\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n",
    "from auxiliar_funcs import *\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from aux_network import build_network_model, bipartite_projection\n",
    "from aux_plot import calculate_log_binning\n",
    "from aux_coms import sub_community_detection, add_type_commts\n",
    "from math import log2, ceil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# User attr: 5\n",
      "# Rsrc attr: 6\n",
      "\n",
      "***** POSITIVE HC *****\n",
      "Columns:  Index(['action', 'role', 'type', 'oward', 'uward', 'team', 'treatingteam',\n",
      "       'patient', 'author', 'topic', 'specialty', 'agentfor', 'user'],\n",
      "      dtype='object')\n",
      "Length:  17888\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 17888 entries, 0 to 17999\n",
      "Data columns (total 13 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   action        17888 non-null  object\n",
      " 1   role          17888 non-null  object\n",
      " 2   type          17888 non-null  object\n",
      " 3   oward         17888 non-null  object\n",
      " 4   uward         17888 non-null  object\n",
      " 5   team          17888 non-null  object\n",
      " 6   treatingteam  17888 non-null  object\n",
      " 7   patient       17888 non-null  object\n",
      " 8   author        17888 non-null  object\n",
      " 9   topic         17888 non-null  object\n",
      " 10  specialty     17888 non-null  object\n",
      " 11  agentfor      17888 non-null  object\n",
      " 12  user          17888 non-null  object\n",
      "dtypes: object(13)\n",
      "memory usage: 1.9+ MB\n",
      "None\n",
      "    action    role    type    oward    uward      team treatingteam  patient  \\\n",
      "0  addnote       ?      hr  oncward  oncward  carteam2     oncteam2  carpat1   \n",
      "1  additem       ?       ?        ?  oncward  carteam1     oncteam2  carpat1   \n",
      "2        ?   nurse       ?  oncward        ?  oncteam2            ?  oncpat2   \n",
      "3  additem   nurse       ?  oncward  carward  oncteam2     carteam2  carpat1   \n",
      "4  addnote  doctor  hritem  oncward  carward  carteam1     carteam1  carpat2   \n",
      "\n",
      "      author    topic specialty agentfor       user  \n",
      "0  carnurse2     note   nursing  carpat2  carnurse1  \n",
      "1  carnurse2  nursing   nursing        ?    oncpat2  \n",
      "2  oncnurse1     note      note  carpat1  oncnurse2  \n",
      "3  carnurse1     note      note  oncpat1    oncdoc2  \n",
      "4  oncnurse1     note   nursing        ?  carnurse2  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Re-order columns by user attributes and resources attributes\n",
    "user_attr = ['role', 'specialty', 'team', 'uward', 'agentfor']\n",
    "rsrc_attr = ['type', 'patient', 'treatingteam', 'oward', 'author', 'topic']\n",
    "print(\"# User attr:\", len(user_attr))\n",
    "print(\"# Rsrc attr:\", len(rsrc_attr))\n",
    "print()\n",
    "\n",
    "##### Load positive access log. #####\n",
    "url_file = \"../00-Data/HC-AccessLog.csv\"\n",
    "df = pd.read_csv(url_file)\n",
    "df = df[df.columns[:-1]].drop_duplicates()\n",
    "print(\"***** POSITIVE HC *****\")\n",
    "print(\"Columns: \", df.columns)\n",
    "print(\"Length: \", len(df))\n",
    "print(df.info())\n",
    "print(df.head(5))\n",
    "print(); print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['role', 'type', 'oward', 'uward', 'team', 'treatingteam', 'patient',\n",
       "       'author', 'topic', 'specialty', 'agentfor'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_values = 0\n",
    "for col in df.columns:\n",
    "    sum_values += len(df[col].drop_duplicates())\n",
    "sum_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# User attr: 5\n",
      "# Rsrc attr: 6\n",
      "\n",
      "***** POSITIVE HC *****\n",
      "Columns:  Index(['action', 'role', 'type', 'oward', 'uward', 'team', 'treatingteam',\n",
      "       'patient', 'author', 'topic', 'specialty', 'agentfor'],\n",
      "      dtype='object')\n",
      "Length:  8735\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8735 entries, 0 to 8998\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   action        8735 non-null   int64 \n",
      " 1   role          8735 non-null   object\n",
      " 2   type          8735 non-null   object\n",
      " 3   oward         8735 non-null   object\n",
      " 4   uward         8735 non-null   object\n",
      " 5   team          8735 non-null   object\n",
      " 6   treatingteam  8735 non-null   object\n",
      " 7   patient       8735 non-null   object\n",
      " 8   author        8735 non-null   object\n",
      " 9   topic         8735 non-null   object\n",
      " 10  specialty     8735 non-null   object\n",
      " 11  agentfor      8735 non-null   object\n",
      "dtypes: int64(1), object(11)\n",
      "memory usage: 887.1+ KB\n",
      "None\n",
      "   action    role type    oward    uward      team treatingteam  patient  \\\n",
      "0       1    none   hr  oncward  carward  oncteam1     oncteam1  oncpat2   \n",
      "1       1    none   hr  oncward     none  carteam1     carteam1  oncpat1   \n",
      "2       1  doctor   hr  oncward  oncward      none     oncteam2  oncpat1   \n",
      "3       1  doctor   hr     none     none  oncteam1     carteam1  oncpat2   \n",
      "4       1    none   hr     none     none  oncteam1     oncteam1  carpat2   \n",
      "\n",
      "      author     topic   specialty agentfor  \n",
      "0    oncdoc2  oncology        note  oncpat1  \n",
      "1  carnurse1      note        none  oncpat1  \n",
      "2  oncnurse2   nursing  cardiology  oncpat1  \n",
      "3    oncdoc2      note  cardiology  oncpat1  \n",
      "4  oncnurse2  oncology     nursing  carpat1  \n",
      "\n",
      "\n",
      "***** NEGATIVE HC *****\n",
      "Columns:  Index(['action', 'role', 'type', 'oward', 'uward', 'team', 'treatingteam',\n",
      "       'patient', 'author', 'topic', 'specialty', 'agentfor'],\n",
      "      dtype='object')\n",
      "Length:  8998\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8998 entries, 0 to 8999\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   action        8998 non-null   int64 \n",
      " 1   role          8998 non-null   object\n",
      " 2   type          8998 non-null   object\n",
      " 3   oward         8998 non-null   object\n",
      " 4   uward         8998 non-null   object\n",
      " 5   team          8998 non-null   object\n",
      " 6   treatingteam  8998 non-null   object\n",
      " 7   patient       8998 non-null   object\n",
      " 8   author        8998 non-null   object\n",
      " 9   topic         8998 non-null   object\n",
      " 10  specialty     8998 non-null   object\n",
      " 11  agentfor      8998 non-null   object\n",
      "dtypes: int64(1), object(11)\n",
      "memory usage: 913.9+ KB\n",
      "None\n",
      "   action    role    type    oward    uward      team treatingteam  patient  \\\n",
      "0       0    none      hr  oncward  oncward  carteam2     oncteam2  carpat1   \n",
      "1       0    none    none     none  oncward  carteam1     oncteam2  carpat1   \n",
      "2       0   nurse    none  oncward     none  oncteam2         none  oncpat2   \n",
      "3       0   nurse    none  oncward  carward  oncteam2     carteam2  carpat1   \n",
      "4       0  doctor  hritem  oncward  carward  carteam1     carteam1  carpat2   \n",
      "\n",
      "      author    topic specialty agentfor  \n",
      "0  carnurse2     note   nursing  carpat2  \n",
      "1  carnurse2  nursing   nursing     none  \n",
      "2  oncnurse1     note      note  carpat1  \n",
      "3  carnurse1     note      note  oncpat1  \n",
      "4  oncnurse1     note   nursing     none  \n",
      "\n",
      "\n",
      "Columns:  Index(['action', 'role', 'type', 'oward', 'uward', 'team', 'treatingteam',\n",
      "       'patient', 'author', 'topic', 'specialty', 'agentfor'],\n",
      "      dtype='object')\n",
      "Length:  17733\n",
      "\n",
      "% Solicitudes (+): 49.26\n",
      "% Solicitudes (-): 50.74\n",
      "\n",
      "\n",
      "Hecho!\n",
      "- k = 10\n",
      "- Porcentaje Train-Test: 80.0 - 20.0\n",
      "|U|: 1064\n",
      "|R|: 2216\n"
     ]
    }
   ],
   "source": [
    "# Re-order columns by user attributes and resources attributes\n",
    "user_attr = ['role', 'specialty', 'team', 'uward', 'agentfor']\n",
    "rsrc_attr = ['type', 'patient', 'treatingteam', 'oward', 'author', 'topic']\n",
    "print(\"# User attr:\", len(user_attr))\n",
    "print(\"# Rsrc attr:\", len(rsrc_attr))\n",
    "print()\n",
    "\n",
    "##### Load positive access log. #####\n",
    "url_file = \"../00-Data/hc-positive.csv\"\n",
    "df = pd.read_csv(url_file)\n",
    "df = df[df.columns[:-1]].drop_duplicates()\n",
    "print(\"***** POSITIVE HC *****\")\n",
    "print(\"Columns: \", df.columns)\n",
    "print(\"Length: \", len(df))\n",
    "print(df.info())\n",
    "print(df.head(5))\n",
    "print(); print()\n",
    "\n",
    "##### Load positive access log. #####\n",
    "url_file = \"../00-Data/hc-negative.csv\"\n",
    "df_neg = pd.read_csv(url_file)\n",
    "df_neg = df_neg[df_neg.columns[:-2]].drop_duplicates()\n",
    "df_neg = df_neg.replace(\"?\", \"none\")\n",
    "df_neg[\"action\"] = 0\n",
    "print(\"***** NEGATIVE HC *****\")\n",
    "print(\"Columns: \", df_neg.columns)\n",
    "print(\"Length: \", len(df_neg))\n",
    "print(df_neg.info())\n",
    "print(df_neg.head(5))\n",
    "print(); print()\n",
    "\n",
    "##### Concatenar solicitudes + y - #####\n",
    "df_total = pd.concat([df, df_neg])\n",
    "print(\"Columns: \", df_total.columns)\n",
    "print(\"Length: \", len(df_total))\n",
    "print()\n",
    "\n",
    "##### Calcular porcentaje de solicitudes + y - #####\n",
    "print(\"% Solicitudes (+): {:.2f}\".format((len(df)/len(df_total))*100))\n",
    "print(\"% Solicitudes (-): {:.2f}\".format((len(df_neg)/len(df_total))*100))\n",
    "print(); print()\n",
    "\n",
    "# Cross-Validation\n",
    "k = 10\n",
    "test_size = 0.2\n",
    "kfold = StratifiedShuffleSplit(n_splits=k, test_size=test_size, random_state=1)\n",
    "\n",
    "data_partition = kfold.split(df_total, df_total.action)\n",
    "data_corpus = [] # Lista donde se almacenan los k fols\n",
    "\n",
    "for train_data, test_data in data_partition:        \n",
    "    X_train, X_test = df_total.iloc[train_data], df_total.iloc[test_data]\n",
    "    data_corpus.append([X_train, X_test])\n",
    "\n",
    "print(\"Hecho!\")\n",
    "print(\"- k =\",k)\n",
    "print(\"- Porcentaje Train-Test:\", (1-test_size)*100, \"-\", test_size*100)\n",
    "\n",
    "print(\"|U|:\", len(df[user_attr].drop_duplicates()))\n",
    "print(\"|R|:\", len(df[rsrc_attr].drop_duplicates()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Solicitudes Train: 14186  %: 80.00\n",
      "# Solicitudes Test: 3547  %: 20.00\n",
      "# Solicitudes: 17733\n",
      "\n",
      "Tarea 1: Tratar valores desconocidos y nulos.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\anaconda3\\envs\\tesis_env\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "c:\\Users\\danie\\anaconda3\\envs\\tesis_env\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n",
      "c:\\Users\\danie\\anaconda3\\envs\\tesis_env\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\Users\\danie\\anaconda3\\envs\\tesis_env\\lib\\site-packages\\ipykernel_launcher.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\Users\\danie\\anaconda3\\envs\\tesis_env\\lib\\site-packages\\ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\Users\\danie\\anaconda3\\envs\\tesis_env\\lib\\site-packages\\ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\Users\\danie\\anaconda3\\envs\\tesis_env\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\Users\\danie\\anaconda3\\envs\\tesis_env\\lib\\site-packages\\ipykernel_launcher.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\Users\\danie\\anaconda3\\envs\\tesis_env\\lib\\site-packages\\ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\Users\\danie\\anaconda3\\envs\\tesis_env\\lib\\site-packages\\ipykernel_launcher.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\Users\\danie\\anaconda3\\envs\\tesis_env\\lib\\site-packages\\ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\Users\\danie\\anaconda3\\envs\\tesis_env\\lib\\site-packages\\ipykernel_launcher.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\Users\\danie\\anaconda3\\envs\\tesis_env\\lib\\site-packages\\ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\Users\\danie\\anaconda3\\envs\\tesis_env\\lib\\site-packages\\ipykernel_launcher.py:43: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\Users\\danie\\anaconda3\\envs\\tesis_env\\lib\\site-packages\\ipykernel_launcher.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\Users\\danie\\anaconda3\\envs\\tesis_env\\lib\\site-packages\\ipykernel_launcher.py:48: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\Users\\danie\\anaconda3\\envs\\tesis_env\\lib\\site-packages\\ipykernel_launcher.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\Users\\danie\\anaconda3\\envs\\tesis_env\\lib\\site-packages\\ipykernel_launcher.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\Users\\danie\\anaconda3\\envs\\tesis_env\\lib\\site-packages\\ipykernel_launcher.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\Users\\danie\\anaconda3\\envs\\tesis_env\\lib\\site-packages\\ipykernel_launcher.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\Users\\danie\\anaconda3\\envs\\tesis_env\\lib\\site-packages\\ipykernel_launcher.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "c:\\Users\\danie\\anaconda3\\envs\\tesis_env\\lib\\site-packages\\ipykernel_launcher.py:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tarea 1: Hecha!.\n",
      "\n",
      "Tarea 2: No aplica!.\n",
      "\n",
      "Tarea 3: Eliminar solicitudes duplicadas.\n",
      "\n",
      "# Solicitudes Train (+): 6988  %: 49.26\n",
      "# Solicitudes Train (-): 7197  %: 50.73\n",
      "# Solicitudes Test (+): 1747  %: 49.25\n",
      "# Solicitudes Test (-): 1800  %: 50.75\n",
      "# Train Users (+):  1046\n",
      "# Train Resrc (+):  2090\n",
      "# Train Users (-):  1045\n",
      "# Train Resrc (-):  1239\n",
      "# Test Users (+):  748\n",
      "# Test Resrc (+):  1\n",
      "# Test Users (-):  826\n",
      "# Test Resrc (-):  407\n"
     ]
    }
   ],
   "source": [
    "id_kfold = 0\n",
    "\n",
    "df_train_k, df_test_k = data_corpus[id_kfold][0], data_corpus[id_kfold][1]\n",
    "print(\"# Solicitudes Train:\", len(df_train_k), \" %: {:.2f}\".format((len(df_train_k)/(len(df_train_k)+len(df_test_k)))*100))\n",
    "print(\"# Solicitudes Test:\", len(df_test_k), \" %: {:.2f}\".format((len(df_test_k)/(len(df_train_k)+len(df_test_k)))*100))\n",
    "print(\"# Solicitudes:\", len(df_train_k)+len(df_test_k))\n",
    "print()\n",
    "\n",
    "n_rsrcs = len(df_train_k[rsrc_attr].drop_duplicates())\n",
    "\n",
    "##### ***** TAREA 1: Tratar valores desconocidos y nulos ***** #####\n",
    "print(\"Tarea 1: Tratar valores desconocidos y nulos.\")\n",
    "# Cambiar valores string a numeros\n",
    "mapping = {\"none\": 10, \"doctor\": 11, \"nurse\": 12} # role\n",
    "df_train_k[\"role\"] = df_train_k[\"role\"].replace(mapping)\n",
    "df_test_k[\"role\"] = df_test_k[\"role\"].replace(mapping)\n",
    "\n",
    "mapping = {\"note\": 110, \"cardiology\": 111, \"nursing\": 112, \"oncology\": 113, \"none\": 114} # speacialty\n",
    "df_train_k[\"specialty\"] = df_train_k[\"specialty\"].replace(mapping)\n",
    "df_test_k[\"specialty\"] = df_test_k[\"specialty\"].replace(mapping)\n",
    "\n",
    "mapping = {\"oncteam1\": 1101, \"carteam1\": 1111,\n",
    "           \"carteam2\": 1121, \"oncteam2\": 1131, \"none\": 1141} # tem\n",
    "df_train_k[\"team\"] = df_train_k[\"team\"].replace(mapping)\n",
    "df_test_k[\"team\"] = df_test_k[\"team\"].replace(mapping)\n",
    "\n",
    "mapping = {\"carward\": 11011, \"oncward\": 11111, \"none\": 11211} # uward\n",
    "df_train_k[\"uward\"] = df_train_k[\"uward\"].replace(mapping)\n",
    "df_test_k[\"uward\"] = df_test_k[\"uward\"].replace(mapping)\n",
    "\n",
    "mapping = {\"oncpat1\": 111011, \"carpat1\": 111111, # agentfor\n",
    "           \"oncpat2\": 111211, \"carpat2\": 111311, \"none\": 111411}\n",
    "df_train_k[\"agentfor\"] = df_train_k[\"agentfor\"].replace(mapping)\n",
    "df_test_k[\"agentfor\"] = df_test_k[\"agentfor\"].replace(mapping)\n",
    "\n",
    "mapping = {\"hr\": 1110111, \"hritem\": 1111111} # type\n",
    "df_train_k[\"type\"] = df_train_k[\"type\"].replace(mapping)\n",
    "df_test_k[\"type\"] = df_test_k[\"type\"].replace(mapping)\n",
    "\n",
    "mapping = {\"oncpat1\": 211012, \"carpat1\": 211112, # patient\n",
    "           \"oncpat2\": 211212, \"carpat2\": 211312, \"none\": 211412}\n",
    "df_train_k[\"patient\"] = df_train_k[\"patient\"].replace(mapping)\n",
    "df_test_k[\"patient\"] = df_test_k[\"patient\"].replace(mapping)\n",
    "\n",
    "mapping = {\"oncteam1\": 2102, \"carteam1\": 2112,\n",
    "           \"carteam2\": 2122, \"oncteam2\": 2132, \"none\": 2142} # treatingteam\n",
    "df_train_k[\"treatingteam\"] = df_train_k[\"treatingteam\"].replace(mapping)\n",
    "df_test_k[\"treatingteam\"] = df_test_k[\"treatingteam\"].replace(mapping)\n",
    "\n",
    "mapping = {\"carward\": 21012, \"oncward\": 21112, \"none\": 21212} # oward\n",
    "df_train_k[\"oward\"] = df_train_k[\"oward\"].replace(mapping)\n",
    "df_test_k[\"oward\"] = df_test_k[\"oward\"].replace(mapping)\n",
    "\n",
    "mapping = {\"note\": 210, \"cardiology\": 211, \"nursing\": 212, \"oncology\": 213, \"none\": 214} # topic\n",
    "df_train_k[\"topic\"] = df_train_k[\"topic\"].replace(mapping)\n",
    "df_test_k[\"topic\"] = df_test_k[\"topic\"].replace(mapping)\n",
    "\n",
    "mapping = {\"oncdoc2\": 11110111, \"carnurse1\": 11111111, \"oncnurse2\": 11112111, # author\n",
    "           \"carnurse2\": 11113111, \"oncdoc1\": 11114111, \"oncnurse1\": 11115111, \"none\": 11116111}\n",
    "df_train_k[\"author\"] = df_train_k[\"author\"].replace(mapping)\n",
    "df_test_k[\"author\"] = df_test_k[\"author\"].replace(mapping)\n",
    "print(\"Tarea 1: Hecha!.\")\n",
    "print()\n",
    "\n",
    "##### ***** TAREA 2: Convertir valores continuas a categoricos ***** #####\n",
    "print(\"Tarea 2: No aplica!.\")\n",
    "print()\n",
    "\n",
    "##### ***** TAREA 3: Eliminar solicitudes duplicadas ***** #####\n",
    "##### Dataframe solicitudes positivas y negativas #####\n",
    "print(\"Tarea 3: Eliminar solicitudes duplicadas.\")\n",
    "df_train_k_pos = df_train_k[df_train_k.action==1]   # Train Pos\n",
    "df_train_k_neg = df_train_k[df_train_k.action==0]   # Train Neg\n",
    "df_test_k_pos = df_test_k[df_test_k.action==1]      # Test Pos\n",
    "df_test_k_neg = df_test_k[df_test_k.action==0]      # Test Neg\n",
    "df_train_k_pos = df_train_k_pos[df_train_k_pos.columns[1:]].drop_duplicates()\n",
    "df_train_k_neg = df_train_k_neg[df_train_k_neg.columns[1:]].drop_duplicates()\n",
    "df_test_k_pos = df_test_k_pos[df_test_k_pos.columns[1:]].drop_duplicates()\n",
    "df_test_k_neg = df_test_k_neg[df_test_k_neg.columns[1:]].drop_duplicates()\n",
    "print()\n",
    "\n",
    "##### Agregar la columna de usuarios y recursos #####\n",
    "user_dict = get_user_res(df_train_k_pos, user_attr, True)\n",
    "res_dict = get_user_res(df_train_k_pos, rsrc_attr, False)\n",
    "df_train_k_pos = add_col(df_train_k_pos, user_dict, user_attr, \"USRID\")\n",
    "df_train_k_pos = add_col(df_train_k_pos, res_dict, rsrc_attr, \"RESID\")\n",
    "df_train_k_neg = add_col(df_train_k_neg, user_dict, user_attr, \"USRID\")\n",
    "df_train_k_neg = add_col(df_train_k_neg, res_dict, rsrc_attr, \"RESID\")\n",
    "df_test_k_pos =  add_col(df_test_k_pos, user_dict, user_attr, \"USRID\")\n",
    "df_test_k_pos =  add_col(df_test_k_pos, res_dict, user_attr, \"RESID\")\n",
    "df_test_k_neg = add_col(df_test_k_neg, user_dict, user_attr, \"USRID\")\n",
    "df_test_k_neg = add_col(df_test_k_neg, res_dict, rsrc_attr, \"RESID\")\n",
    "\n",
    "print(\"# Solicitudes Train (+):\", len(df_train_k_pos), \" %: {:.2f}\".format((len(df_train_k_pos)/len(df_train_k))*100))\n",
    "print(\"# Solicitudes Train (-):\", len(df_train_k_neg), \" %: {:.2f}\".format((len(df_train_k_neg)/len(df_train_k))*100))\n",
    "print(\"# Solicitudes Test (+):\", len(df_test_k_pos), \" %: {:.2f}\".format((len(df_test_k_pos)/len(df_test_k))*100))\n",
    "print(\"# Solicitudes Test (-):\", len(df_test_k_neg), \" %: {:.2f}\".format((len(df_test_k_neg)/len(df_test_k))*100))\n",
    "print(\"# Train Users (+): \", len(df_train_k_pos.USRID.drop_duplicates()))\n",
    "print(\"# Train Resrc (+): \", len(df_train_k_pos.RESID.drop_duplicates()))\n",
    "print(\"# Train Users (-): \", len(df_train_k_neg.USRID.drop_duplicates()))\n",
    "print(\"# Train Resrc (-): \", len(df_train_k_neg.RESID.drop_duplicates()))\n",
    "print(\"# Test Users (+): \", len(df_test_k_pos.USRID.drop_duplicates()))\n",
    "print(\"# Test Resrc (+): \", len(df_test_k_pos.RESID.drop_duplicates()))\n",
    "print(\"# Test Users (-): \", len(df_test_k_neg.USRID.drop_duplicates()))\n",
    "print(\"# Test Resrc (-): \", len(df_test_k_neg.RESID.drop_duplicates()))\n",
    "\n",
    "task4 = False\n",
    "if task4:\n",
    "    # Filter resources\n",
    "    n1 = 0\n",
    "    n2 = 210\n",
    "    top_list = df_train_k_pos.RESID.value_counts()[:n_rsrcs].index.tolist()\n",
    "    # Filter the interval between n1 and n2\n",
    "    top_list = top_list[n1:n2+1]\n",
    "    print('#Filtered resources:', len(top_list))\n",
    "\n",
    "    # B_II Data splitting\n",
    "    boolean_series = df_train_k_pos.RESID.isin(top_list)\n",
    "    df_train_k_pos = df_train_k_pos[boolean_series]\n",
    "    bolean_series = df_train_k_neg.RESID.isin(top_list)\n",
    "    df_train_k_neg = df_train_k_neg[bolean_series]\n",
    "\n",
    "### Create the user and resources dataframes with their attributes.\n",
    "df_user_attrs = df_train_k_pos[user_attr+[\"USRID\"]].drop_duplicates()\n",
    "df_rscs_attrs = df_train_k_pos[rsrc_attr+[\"RESID\"]].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IGRAPH UN-- 3136 6988 -- \n",
      "+ attr: name (v)\n",
      "<igraph.VertexSeq object at 0x0000022B14F2DB88>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARBN builded!\n",
      "IGRAPH UN-- 3136 6988 -- \n",
      "+ attr: name (v), typen (v)\n",
      "|U-Nodes| = 1046\n",
      "|R-Nodes| = 2090\n"
     ]
    }
   ],
   "source": [
    "bip_network = build_network_model(df_train_k_pos, 'USRID', 'RESID',\n",
    "                                  df_user_attrs, df_rscs_attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IGRAPH UNW- 1032 19509 -- \n",
      "+ attr: name (v), rsrcs (v), weight (e)\n"
     ]
    }
   ],
   "source": [
    "user_network = bipartite_projection(bip_network, 0)\n",
    "print(user_network.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add features to the user network\n",
    "\n",
    "user_data_attrs = df_train_k_pos[user_attr+[\"USRID\"]].drop_duplicates()\n",
    "#user_data_attrs[user_data_attrs.USRID == 101]\n",
    "role_attr = []\n",
    "specialty_attr = []\n",
    "team_attr = []\n",
    "uward_attr = []\n",
    "agentfor_attr = []\n",
    "for user in user_network.vs():\n",
    "    user_row = user_data_attrs[user_data_attrs.USRID == user['name']]    \n",
    "    role_attr.append(user_row['role'].values[0])\n",
    "    specialty_attr.append(user_row['specialty'].values[0])\n",
    "    team_attr.append(user_row['team'].values[0])\n",
    "    uward_attr.append(user_row['uward'].values[0])\n",
    "    agentfor_attr.append(user_row['agentfor'].values[0])\n",
    "    \n",
    "user_network.vs['role'] = role_attr\n",
    "user_network.vs['specialty'] = specialty_attr\n",
    "user_network.vs['team'] = team_attr\n",
    "user_network.vs['uward'] = uward_attr\n",
    "user_network.vs['agentfor'] = agentfor_attr\n",
    "user_network.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
