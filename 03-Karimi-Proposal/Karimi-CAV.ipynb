{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DO NOT CHANGE THIS CODE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, StratifiedShuffleSplit\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from auxiliar_funcs import *\n",
    "\n",
    "import pmtools2 as pm\n",
    "import kmodes\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns:  Index(['driving_task_type', 'control', 'monitoring', 'fallback', 'weather',\n",
      "       'visibility', 'traffic_congestion', 'environmental_weighted_average',\n",
      "       'driving_task_loa', 'vehicle_loa', 'region_loa', 'result'],\n",
      "      dtype='object')\n",
      "Lenght:  239580\n",
      "\n",
      "# User attr: 6\n",
      "# Rsrc attr: 3\n",
      "\n",
      "|U| = 6655\n",
      "|R| = 216\n",
      "\n",
      "|L+| = 118975 49.66%\n",
      "|L-| = 120605 50.34%\n",
      "Done!\n",
      " - k = 10\n",
      " - Train-Test size:  191664 ( 80.0 ) \t 47916 ( 20.0 )\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "url_file = '../00-Data/cav_policies.csv'\n",
    "cav_data = pd.read_csv(url_file)\n",
    "\n",
    "# Get a smaller sample: 15K positive and 15k negative.\n",
    "# cav_data = cav_data.groupby('result').sample(n=15000)\n",
    "print(\"Columns: \", cav_data.columns)\n",
    "print(\"Lenght: \", len(cav_data)); print()\n",
    "\n",
    "user_attr = ['control', 'monitoring', 'fallback', 'weather', 'visibility', \n",
    "        'traffic_congestion']\n",
    "#user_attr = ['control', 'monitoring', 'fallback']\n",
    "rsrc_attr = ['driving_task_loa', 'vehicle_loa', 'region_loa']\n",
    "cav_data = cav_data[user_attr + rsrc_attr + ['result']]\n",
    "\n",
    "# Change string values to numerical\n",
    "mapping = {'system': 10101, 'human': 10201, 'human and system': 10301} # Control\n",
    "cav_data.control = cav_data.control.replace(mapping)\n",
    "\n",
    "mapping = {'system': 20102, 'human': 20202} # monitoring\n",
    "cav_data.monitoring = cav_data.monitoring.replace(mapping)\n",
    "\n",
    "mapping = {'system': 30103, 'human': 30203} # fallbacj\n",
    "cav_data.fallback = cav_data.fallback.replace(mapping)\n",
    "\n",
    "mapping = {0: 40004, 1: 40104, 2: 40204, 3: 40304, 4: 40404, 5: 40504}\n",
    "cav_data.driving_task_loa = cav_data.driving_task_loa.replace(mapping)\n",
    "\n",
    "mapping = {0: 50005, 1: 50105, 2: 50205, 3: 50305, 4: 50405, 5: 50505}\n",
    "cav_data.vehicle_loa = cav_data.vehicle_loa.replace(mapping)\n",
    "\n",
    "mapping = {0: 60006, 1: 60106, 2: 60206, 3: 60306, 4: 60406, 5: 60506}\n",
    "cav_data.region_loa = cav_data.region_loa.replace(mapping)\n",
    "\n",
    "\n",
    "print(\"# User attr:\", len(user_attr))\n",
    "print(\"# Rsrc attr:\", len(rsrc_attr)); print()\n",
    "\n",
    "# Data statictics:\n",
    "n_users = len(cav_data[user_attr].drop_duplicates())\n",
    "n_rscrc = len(cav_data[rsrc_attr].drop_duplicates())\n",
    "print(\"|U| =\", n_users)\n",
    "print(\"|R| =\", n_rscrc); print()\n",
    "\n",
    "# Add user and resource id columns\n",
    "user_dict = get_user_res(cav_data, user_attr, True)\n",
    "rsrc_dict = get_user_res(cav_data, rsrc_attr, False)\n",
    "cav_data = add_col(cav_data, user_dict, user_attr, \"USRID\")\n",
    "cav_data = add_col(cav_data, rsrc_dict, rsrc_attr, \"RESID\")\n",
    "\n",
    "# Accepted and rejected requests\n",
    "cav_pos = cav_data[cav_data.result == 'approved']\n",
    "cav_neg = cav_data[cav_data.result == 'rejected']\n",
    "print(\"|L+| =\", len(cav_pos), \"{:.2f}%\".format((len(cav_pos) \n",
    "        / len(cav_data) ) * 100))\n",
    "print(\"|L-| =\", len(cav_neg), \"{:.2f}%\".format((len(cav_neg) \n",
    "        / len(cav_data) ) * 100))\n",
    "\n",
    "# Cross validation\n",
    "k = 10\n",
    "test_size = 0.2\n",
    "kfold = StratifiedShuffleSplit(n_splits=k, test_size=test_size, random_state=1)\n",
    "\n",
    "data_partition = kfold.split(cav_data, cav_data.result)\n",
    "data_curpus = [] # A list to storage the k folds\n",
    "\n",
    "for train_data, test_data in data_partition:\n",
    "    X_train, X_test = cav_data.iloc[train_data], cav_data.iloc[test_data]\n",
    "    data_curpus.append([X_train, X_test])\n",
    "\n",
    "print(\"Done!\")  \n",
    "print(\" - k =\", k)\n",
    "print(\" - Train-Test size: \", len(data_curpus[0][0]), \"(\", (1-test_size)*100, \") \\t\", len(data_curpus[0][1]), \"(\", test_size*100, \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Train access request = 191664 80.00%\n",
      "# Train access request = 47916 80.00%\n",
      "Total = 239580\n",
      "\n",
      "TASK 1: Done!\n",
      "\n",
      "TASK 2: Done!\n",
      "\n",
      "TASK 3: Drop duplicates access requests\n",
      " -TRAIN DATA: Removing 0 positive access requests\n",
      " -TRAIN DATA: Removing 0 negative access requests\n",
      " -TEST DATA: Removing 0 positive access requests\n",
      " -TEST DATA: Removing 0 negative access requests\n",
      "Hecho!\n"
     ]
    }
   ],
   "source": [
    "id_kfold = 1\n",
    "\n",
    "cav_train, cav_test = data_curpus[id_kfold][0], data_curpus[id_kfold][1]\n",
    "print(\"# Train access request =\", len(cav_train), \"{:.2f}%\".format(\n",
    "    len(cav_train)/(len(cav_train)+len(cav_test))*100))\n",
    "print(\"# Train access request =\", len(cav_test), \"{:.2f}%\".format(\n",
    "    len(cav_train)/(len(cav_train)+len(cav_test))*100))\n",
    "print(\"Total =\", len(cav_train)+len(cav_test)); print()\n",
    "\n",
    "#### **** SELECT FUNCTIONAL ATTRIBUTES **** ####\n",
    "cav_train = cav_train[user_attr + rsrc_attr + ['USRID', 'RESID', 'result']]\n",
    "cav_test = cav_test[user_attr + rsrc_attr + ['USRID', 'RESID', 'result']]\n",
    "\n",
    "##### ***** Task 1: Null and uknwokn values ***** #####\n",
    "print(\"TASK 1: Done!\"); print() # NA\n",
    "\n",
    "\n",
    "##### ***** TASK 2: convert continuous values to categorical values ***** #####\n",
    "print(\"TASK 2: Done!\"); print() # NA \n",
    "\n",
    "##### ***** TASK 3: Drop duplicates access requests ***** #####\n",
    "print(\"TASK 3: Drop duplicates access requests\")\n",
    "\n",
    "positive_cav_train = cav_train[cav_train.result=='approved']\n",
    "positive_cav_test = cav_test[cav_test.result=='approved']\n",
    "negative_cav_train = cav_train[cav_train.result=='rejected']\n",
    "negative_cav_test = cav_test[cav_test.result=='rejected']\n",
    "\n",
    "\n",
    "print(\" -TRAIN DATA: Removing\", \n",
    "    len(positive_cav_train.drop_duplicates()) - \n",
    "    len(positive_cav_train), \"positive access requests\")\n",
    "print(\" -TRAIN DATA: Removing\", \n",
    "    len(negative_cav_train.drop_duplicates()) - \n",
    "    len(negative_cav_train), \"negative access requests\")\n",
    "print(\" -TEST DATA: Removing\", \n",
    "    len(positive_cav_test.drop_duplicates()) - \n",
    "    len(positive_cav_test), \"positive access requests\")\n",
    "print(\" -TEST DATA: Removing\", \n",
    "    len(negative_cav_test.drop_duplicates()) - \n",
    "    len(negative_cav_test), \"negative access requests\")\n",
    "\n",
    "# Filter resources\n",
    "#bolean_series = negative_cav_train.RESID.isin(top_list)\n",
    "#negative_cav_train = negative_cav_train[bolean_series]\n",
    "print(\"Hecho!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready!\n"
     ]
    }
   ],
   "source": [
    "###Select the number of clusters###\n",
    "num_clusters = 20\n",
    "\n",
    "#DO NOT CHANGE THIS CODE\n",
    "# seed = 29\n",
    "\n",
    "#Compute centroids and labels\n",
    "# num_init = 5\n",
    "centroids = []\n",
    "kmodes_huang = kmodes.KModes(n_clusters=num_clusters, init='Huang', verbose=0)\n",
    "cluster_labels = kmodes_huang.fit_predict(positive_cav_train)\n",
    "centroids = kmodes_huang.cluster_centroids_\n",
    "\n",
    "print('Ready!')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/tesis_env/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "positive_cav_train[\"cls\"] = cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq(value, attribute, dataplace):\n",
    "    \"\"\"\n",
    "    Calculate the frequency of the value in the dataplace.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    value : int\n",
    "        Value to compute its frequency.\n",
    "\n",
    "    attribute : string\n",
    "        Name of the attribute.\n",
    "\n",
    "    dataplace : DataFrame pandas\n",
    "        Data to search.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float [0-1]\n",
    "        Returns the value of frequency of the value in the data.\n",
    "    \"\"\"\n",
    "    value_freq = dataplace[dataplace[attribute] == value].drop_duplicates()\n",
    "    return len(value_freq) / len(dataplace)\n",
    "\n",
    "def freq_rels(attrA, attrB, dataplace):\n",
    "    \"\"\"\n",
    "    Compute the frequency of the attribute relation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    attrA : string\n",
    "        Name of the attribute A to compare.\n",
    "    attrB : string\n",
    "        Name of the attribute B to compare.\n",
    "    dataplace : DataFrame pandas\n",
    "        Data to search.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float [0-1]\n",
    "        Returns the value of frequency of the range of values in the data.\n",
    "    \"\"\"\n",
    "    # Get the range of values of attribute A.\n",
    "    range_val_A = set(dataplace[attrA].values.tolist())\n",
    "\n",
    "    # Get the range of values of attribute B.\n",
    "    range_val_B = set(dataplace[attrB].values.tolist())\n",
    "\n",
    "    # Check if the len\n",
    "    if len(range_val_A) == len(range_val_B):\n",
    "        # Compute the intersection\n",
    "        inter_A_B = range_val_A.intersection(range_val_B)\n",
    "        if len(inter_A_B) == len(range_val_A):\n",
    "            boolean_series = dataplace[attrA].isin(inter_A_B)\n",
    "            frac_log = dataplace[boolean_series]\n",
    "            return len(frac_log) / len(dataplace) # Return the fraction\n",
    "        return 0\n",
    "    else:\n",
    "        return 0    \n",
    "\n",
    "def extract_attributes_filters(C_i, A, L, posThr, negThr):\n",
    "    \"\"\"\n",
    "    Effective attribute extraction algorithm. Generate a rule for each cluster.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    C_i : DataFrame pandas\n",
    "        Access request in the Cluster i.\n",
    "\n",
    "    A : List\n",
    "        List of attributes.\n",
    "\n",
    "    V : List\n",
    "        Values of attributes.\n",
    "\n",
    "    L : DataFrame\n",
    "        Complete Access Log.\n",
    "\n",
    "    PosThr : float\n",
    "        Positive Threshold to the effective positive attribute.\n",
    "\n",
    "    NegThr : float\n",
    "        Negative Threshold to the effective negative attribute.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        Returns the rule with the effective attributes for the cluster i.\n",
    "    \"\"\"\n",
    "    filter_to_ret = [] # Rule\n",
    "    for a in A:        \n",
    "        a_values = C_i[a].drop_duplicates().tolist()        \n",
    "        for v in a_values:\n",
    "            if freq(v, a, C_i) - freq(v, a, L) > posThr:\n",
    "                if not [a, v] in filter_to_ret:\n",
    "                    filter_to_ret.append([a, v])\n",
    "            if freq(v, a, L) - freq(v, a, C_i) > negThr:\n",
    "                if not [a, -1*v] in filter_to_ret:\n",
    "                    filter_to_ret.append([a, v*-1])\n",
    "    return filter_to_ret\n",
    "\n",
    "def extract_relations(C_i, A, L, posThr, negThr):\n",
    "    \"\"\"\n",
    "    Extract the effective relation. For each cluster.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    C_i : DataFrame pandas\n",
    "        Access request in the Cluster i.\n",
    "\n",
    "    A : List\n",
    "        List of attributes.\n",
    "\n",
    "    L : DataFrame\n",
    "        Complete Access Log.\n",
    "\n",
    "    posThr : float\n",
    "        Positive Threshold to the effective positive relation.\n",
    "\n",
    "    negThr : float\n",
    "        Negative Threshold to the effective negative relation.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        Returns the rule with the effective relation for the cluster i.\n",
    "    \"\"\"\n",
    "    relation_to_ret = []\n",
    "    for a in A:\n",
    "        for b in A:\n",
    "            if a != b:\n",
    "                if freq_rels(a, b, C_i) - freq_rels(a, b, L) > posThr:\n",
    "                    if not [a, b] in relation_to_ret:\n",
    "                        relation_to_ret.append([a, b])\n",
    "                if freq_rels(a, b, L) - freq_rels(a, b, C_i) > negThr:\n",
    "                    if not [a, '!'+b] in relation_to_ret:                        \n",
    "                        relation_to_ret.append([a, '!'+b])\n",
    "                    #print()\n",
    "\n",
    "def rule_inference(data_, pos_attr_thr, \n",
    "    neg_attr_thr, pos_rel_thr, neg_rel_thr):\n",
    "    rule_list = [] # All rules\n",
    "    n_cluster = len(data_[\"cls\"].drop_duplicates()) # N clusters\n",
    "    attrs = data_.columns[:-1] # Name of the columns\n",
    "\n",
    "    for C_i in range(n_cluster):\n",
    "        #print(C_i)\n",
    "        rule_i = []\n",
    "        data_cluster = data_[data_[\"cls\"] == C_i]\n",
    "        \n",
    "        # Effective attributes\n",
    "        attr_filters = extract_attributes_filters(data_cluster, attrs, data_, \n",
    "            pos_attr_thr, neg_attr_thr)    \n",
    "        rule_i.append(attr_filters)        \n",
    "\n",
    "        # Relations\n",
    "        attr_relation = extract_relations(data_cluster, attrs, data_, \n",
    "            pos_rel_thr, neg_rel_thr)\n",
    "        rule_i.append(attr_relation)\n",
    "        #print(rule_i)\n",
    "\n",
    "        rule_list.append([C_i, rule_i])    \n",
    "\n",
    "    return rule_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['monitoring', 'fallback', 'weather', 'visibility', 'traffic_congestion',\n",
       "       'driving_task_loa', 'vehicle_loa', 'region_loa', 'cls'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = positive_cav_train[['monitoring', 'fallback', 'weather', 'visibility', 'traffic_congestion',\n",
    "       'driving_task_loa', 'vehicle_loa', 'region_loa', 'cls']]\n",
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_attr_thr = 0.3\n",
    "neg_attr_thr = 0.2\n",
    "pos_rel_thr = 0.2\n",
    "neg_rel_thr = 0.2\n",
    "test = rule_inference(df_test, pos_attr_thr, neg_attr_thr, pos_rel_thr, neg_attr_thr)\n",
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_rules = []\n",
    "for rule in test:\n",
    "    only_rules.append(rule[1][0])\n",
    "len(only_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute how many rules has a lenght equal to 1.\n",
    "for idx, rule in enumerate(only_rules):\n",
    "    if len(rule) < 2:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del only_rules[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa FN: 24.07\n",
      "FN:  22912  de  95180\n"
     ]
    }
   ],
   "source": [
    "false_neg  = []\n",
    "for i,row in positive_cav_train.iterrows():\n",
    "    \n",
    "    # Evaluaci贸n\n",
    "    denies_count = 0    \n",
    "    for rule in only_rules:                                      \n",
    "        # En esta parte se evalua la regla completa\n",
    "        res = True\n",
    "        \n",
    "        #for idx_r, attr_val in enumerate(rule):\n",
    "        for attr_val in rule:            \n",
    "            if attr_val[1] < 0:\n",
    "                if row[attr_val[0]] == attr_val[1]*-1:\n",
    "                    res = False\n",
    "                    break\n",
    "            else:\n",
    "                if row[attr_val[0]] != attr_val[1]:\n",
    "                    res = False\n",
    "                    break\n",
    "        if res == False:\n",
    "            denies_count += 1\n",
    "    \n",
    "    if denies_count == len(only_rules):\n",
    "        false_neg.append(row)\n",
    "        #print(\"FP-2\")\n",
    "\n",
    "FN = len(false_neg)\n",
    "print(\"Tasa FN: {:.2f}\".format((FN/ len(positive_cav_train))*100))\n",
    "print(\"FN: \", FN, \" de \", len(positive_cav_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa FP: 40.68\n",
      "FN:  39251  de  96484\n"
     ]
    }
   ],
   "source": [
    "false_pos  = []\n",
    "for i,row in negative_cav_train.iterrows():\n",
    "    # Evaluaci贸n\n",
    "    denies_count = 0\n",
    "    temp_rules_n = 0\n",
    "    for rule in only_rules:                                      \n",
    "        # En esta parte se evalua la regla completa\n",
    "        res = True                        \n",
    "        for attr_val in rule:\n",
    "            if attr_val[1] < 0:\n",
    "                if row[attr_val[0]] == attr_val[1]*-1:\n",
    "                    res = False\n",
    "                    break\n",
    "            else:\n",
    "                if row[attr_val[0]] != attr_val[1]:\n",
    "                    res = False\n",
    "                    break\n",
    "        if res == False:\n",
    "            denies_count += 1                                \n",
    "    #print(\"XXX-\", denies_count, temp_rules_n, res)\n",
    "    if denies_count < len(only_rules):\n",
    "        false_pos.append(row)\n",
    "        #print(\"FP-2\")    \n",
    "    #else:\n",
    "    #    print(\"ENtra PAPA\")\n",
    "    \n",
    "FP = len(false_pos)\n",
    "print(\"Tasa FP: {:.2f}\".format((FP/ len(negative_cav_train))*100))\n",
    "print(\"FN: \", FP, \" de \", len(negative_cav_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FN: 22912  - 24.07\n",
      "FP: 39251  - 40.68\n",
      "Precision: 0.6480330705978353\n",
      "Recall: 0.7592771590670309\n",
      "F-score 0.699258341840067\n",
      "# Rules: 20\n",
      "WSC: 79\n"
     ]
    }
   ],
   "source": [
    "\n",
    "TP = len(positive_cav_train) - FN\n",
    "#TP = 50 - FN\n",
    "TN = len(negative_cav_train) - FP\n",
    "#TN = 50 - FP\n",
    "\n",
    "precision = TP / (TP + FP)\n",
    "\n",
    "recall = TP / (TP + FN)\n",
    "\n",
    "fscore = 2*(precision*recall)/(precision+recall)\n",
    "\n",
    "print(\"FN:\", FN, \" - {:.2f}\".format((FN/len(positive_cav_train))*100))\n",
    "#print(\"FN:\", FN, \" - {:.2f}\".format((FN/50)*100))\n",
    "print(\"FP:\", FP, \" - {:.2f}\".format((FP/len(negative_cav_train))*100))\n",
    "#print(\"FP:\", FP, \" - {:.2f}\".format((FP/50)*100))\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F-score\", fscore)\n",
    "\n",
    "def compute_wsc(policy):\n",
    "    return sum([len(rule) for rule in policy])\n",
    "\n",
    "print(\"# Rules:\", len(only_rules))\n",
    "print(\"WSC:\", compute_wsc(only_rules))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_rule_to_str(rule):\n",
    "    rule_str = []\n",
    "    #print(rule)\n",
    "    for item in rule:\n",
    "        rule_str.append(item[0]+'*'+str(item[1]))\n",
    "    return set(rule_str)\n",
    "\n",
    "def convert_set_to_list(rule):\n",
    "    rule_list = []    \n",
    "    for item in rule:\n",
    "        rule_list.append([item.split('*')[0], int(item.split('*')[1])])\n",
    "    return rule_list\n",
    "\n",
    "def jaccard_similarity(rule_i, rule_j):\n",
    "\n",
    "    #transofrm data\n",
    "    rule_i_str = convert_rule_to_str(rule_i)\n",
    "    rule_j_str = convert_rule_to_str(rule_j)\n",
    "\n",
    "    intersection = len(list(set(rule_i_str).intersection(rule_j_str)))\n",
    "    union = len(list(set(rule_i_str).union(rule_j_str)))\n",
    "    return float( intersection / union ) \n",
    "\n",
    "def get_similar_rules(rule_i, all_rules):\n",
    "    similar_rules = []\n",
    "    for rule_j in all_rules:\n",
    "        # Jaccard similarity\n",
    "        jaccard_sim = jaccard_similarity(rule_i, rule_j)\n",
    "        if jaccard_sim > 0.5:\n",
    "            similar_rules.append(rule_j)\n",
    "\n",
    "    return similar_rules\n",
    "\n",
    "def fn_refine_policy(fn_rules, all_rules):\n",
    "    new_rules = all_rules\n",
    "    for rule in fn_rules:\n",
    "        \n",
    "        similar_rules = get_similar_rules(rule, all_rules)\n",
    "\n",
    "        if len(similar_rules) == 0:\n",
    "            new_rules.append(rule)\n",
    "        else:\n",
    "            for sim_rule in similar_rules:\n",
    "                rule_str = convert_rule_to_str(rule)\n",
    "                rule_str_sim = convert_rule_to_str(sim_rule)\n",
    "\n",
    "                new_filter = rule_str_sim.difference((rule_str_sim.difference(rule_str)))\n",
    "                print(new_filter)\n",
    "                new_list_filter = convert_set_to_list(new_filter)\n",
    "                idx_to_del = new_rules.index(sim_rule)\n",
    "                del new_rules[idx_to_del]\n",
    "                new_rules.append(new_list_filter)\n",
    "    \n",
    "    return new_rules\n",
    "                \n",
    "\n",
    "def fp_refine_policy(fp_rules, all_rules):\n",
    "    new_rules = all_rules\n",
    "    for rule in fp_rules:\n",
    "        \n",
    "        similar_rules = get_similar_rules(rule, all_rules)\n",
    "\n",
    "        if len(similar_rules) != 0:                    \n",
    "            for sim_rule in similar_rules:\n",
    "                rule_str = convert_rule_to_str(rule)\n",
    "                rule_str_sim = convert_rule_to_str(sim_rule)\n",
    "\n",
    "                new_filter = rule_str_sim.difference((rule_str_sim.difference(rule_str)))\n",
    "                new_list_filter = convert_set_to_list(new_filter)\n",
    "                idx_to_del = new_rules.index(sim_rule)\n",
    "                del new_rules[idx_to_del]\n",
    "                new_rules.append(new_list_filter)\n",
    "    \n",
    "    return new_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_neg = pd.DataFrame(false_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready!\n"
     ]
    }
   ],
   "source": [
    "###Select the number of clusters###\n",
    "num_clusters = 5\n",
    "\n",
    "#DO NOT CHANGE THIS CODE\n",
    "# seed = 29\n",
    "\n",
    "#Compute centroids and labels\n",
    "# num_init = 5\n",
    "centroids = []\n",
    "kmodes_huang = kmodes.KModes(n_clusters=num_clusters, init='Huang', verbose=0)\n",
    "cluster_labels = kmodes_huang.fit_predict(false_neg)\n",
    "centroids = kmodes_huang.cluster_centroids_\n",
    "\n",
    "print('Ready!')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_neg[\"cls\"] = cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_2 = false_neg[['monitoring', 'fallback', 'weather', 'visibility', 'traffic_congestion',\n",
    "       'driving_task_loa', 'vehicle_loa', 'region_loa', 'cls']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_attr_thr = 0.3\n",
    "neg_attr_thr = 0.2\n",
    "pos_rel_thr = 0.2\n",
    "neg_rel_thr = 0.2\n",
    "test = rule_inference(df_test_2, pos_attr_thr, neg_attr_thr, pos_rel_thr, neg_attr_thr)\n",
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_rules_2 = []\n",
    "for rule in test:\n",
    "    only_rules_2.append(rule[1][0])\n",
    "len(only_rules_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute how many rules has a lenght equal to 1.\n",
    "for idx, rule in enumerate(only_rules_2):\n",
    "    if len(rule) < 2:\n",
    "        print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'driving_task_loa*40004', 'driving_task_loa*-40104', 'region_loa*-60506'}\n",
      "{'driving_task_loa*40004', 'driving_task_loa*-40104', 'region_loa*-60506'}\n",
      "{'driving_task_loa*40004', 'driving_task_loa*-40104', 'region_loa*60306', 'region_loa*-60506'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_rules = fn_refine_policy(only_rules_2, only_rules)\n",
    "len(new_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa FN: 8.68\n",
      "FN:  8262  de  95180\n"
     ]
    }
   ],
   "source": [
    "false_neg  = []\n",
    "for i,row in positive_cav_train.iterrows():\n",
    "    \n",
    "    # Evaluaci贸n\n",
    "    denies_count = 0    \n",
    "    for rule in new_rules:                                      \n",
    "        # En esta parte se evalua la regla completa\n",
    "        res = True\n",
    "        \n",
    "        #for idx_r, attr_val in enumerate(rule):\n",
    "        for attr_val in rule:            \n",
    "            if attr_val[1] < 0:\n",
    "                if row[attr_val[0]] == attr_val[1]*-1:\n",
    "                    res = False\n",
    "                    break\n",
    "            else:\n",
    "                if row[attr_val[0]] != attr_val[1]:\n",
    "                    res = False\n",
    "                    break\n",
    "        if res == False:\n",
    "            denies_count += 1\n",
    "    \n",
    "    if denies_count == len(new_rules):\n",
    "        false_neg.append(row)\n",
    "        #print(\"FP-2\")\n",
    "\n",
    "FN = len(false_neg)\n",
    "print(\"Tasa FN: {:.2f}\".format((FN/ len(positive_cav_train))*100))\n",
    "print(\"FN: \", FN, \" de \", len(positive_cav_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa FP: 47.34\n",
      "FN:  45679  de  96484\n"
     ]
    }
   ],
   "source": [
    "false_pos  = []\n",
    "for i,row in negative_cav_train.iterrows():\n",
    "    # Evaluaci贸n\n",
    "    denies_count = 0\n",
    "    temp_rules_n = 0\n",
    "    for rule in new_rules:                                      \n",
    "        # En esta parte se evalua la regla completa\n",
    "        res = True                        \n",
    "        for attr_val in rule:\n",
    "            if attr_val[1] < 0:\n",
    "                if row[attr_val[0]] == attr_val[1]*-1:\n",
    "                    res = False\n",
    "                    break\n",
    "            else:\n",
    "                if row[attr_val[0]] != attr_val[1]:\n",
    "                    res = False\n",
    "                    break\n",
    "        if res == False:\n",
    "            denies_count += 1                                \n",
    "    #print(\"XXX-\", denies_count, temp_rules_n, res)\n",
    "    if denies_count < len(new_rules):\n",
    "        false_pos.append(row)\n",
    "        #print(\"FP-2\")    \n",
    "    #else:\n",
    "    #    print(\"ENtra PAPA\")\n",
    "FP = len(false_pos)\n",
    "print(\"Tasa FP: {:.2f}\".format((FP/ len(negative_cav_train))*100))\n",
    "print(\"FN: \", FP, \" de \", len(negative_cav_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FN: 8262  - 8.68\n",
      "FP: 45679  - 47.34\n",
      "Precision: 0.6555050265088954\n",
      "Recall: 0.91319604959025\n",
      "F-score 0.7631850450221049\n",
      "# Rules: 24\n",
      "WSC: 98\n"
     ]
    }
   ],
   "source": [
    "TP = len(positive_cav_train) - FN\n",
    "#TP = 50 - FN\n",
    "TN = len(negative_cav_train) - FP\n",
    "#TN = 50 - FP\n",
    "\n",
    "precision = TP / (TP + FP)\n",
    "\n",
    "recall = TP / (TP + FN)\n",
    "\n",
    "fscore = 2*(precision*recall)/(precision+recall)\n",
    "\n",
    "print(\"FN:\", FN, \" - {:.2f}\".format((FN/len(positive_cav_train))*100))\n",
    "#print(\"FN:\", FN, \" - {:.2f}\".format((FN/50)*100))\n",
    "print(\"FP:\", FP, \" - {:.2f}\".format((FP/len(negative_cav_train))*100))\n",
    "#print(\"FP:\", FP, \" - {:.2f}\".format((FP/50)*100))\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F-score\", fscore)\n",
    "\n",
    "def compute_wsc(policy):\n",
    "    return sum([len(rule) for rule in policy])\n",
    "\n",
    "print(\"# Rules:\", len(only_rules))\n",
    "print(\"WSC:\", compute_wsc(only_rules))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13 (default, Mar 29 2022, 02:18:16) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "deec884ae07beaa7e970d39d84b9343805b80aeba4e343861fb4097b62dc7004"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
