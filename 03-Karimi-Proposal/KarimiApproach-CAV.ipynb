{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Karimi Proposal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DO NOT CHANGE THIS CODE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold, StratifiedShuffleSplit\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from auxiliar_funcs import *\n",
    "\n",
    "import pmtools2 as pm\n",
    "import kmodes\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns:  Index(['driving_task_type', 'control', 'monitoring', 'fallback', 'weather',\n",
      "       'visibility', 'traffic_congestion', 'environmental_weighted_average',\n",
      "       'driving_task_loa', 'vehicle_loa', 'region_loa', 'result'],\n",
      "      dtype='object')\n",
      "Lenght:  239580\n",
      "\n",
      "# User attr: 6\n",
      "# Rsrc attr: 3\n",
      "\n",
      "|U| = 6655\n",
      "|R| = 216\n",
      "\n",
      "|L+| = 118975 49.66%\n",
      "|L-| = 120605 50.34%\n",
      "Done!\n",
      " - k = 10\n",
      " - Train-Test size:  191664 ( 80.0 ) \t 47916 ( 20.0 )\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "url_file = '../00-Data/cav_policies.csv'\n",
    "cav_data = pd.read_csv(url_file)\n",
    "\n",
    "# Get a smaller sample: 15K positive and 15k negative.\n",
    "# cav_data = cav_data.groupby('result').sample(n=15000)\n",
    "print(\"Columns: \", cav_data.columns)\n",
    "print(\"Lenght: \", len(cav_data)); print()\n",
    "\n",
    "user_attr = ['control', 'monitoring', 'fallback', 'weather', 'visibility', \n",
    "        'traffic_congestion']\n",
    "#user_attr = ['control', 'monitoring', 'fallback']\n",
    "rsrc_attr = ['driving_task_loa', 'vehicle_loa', 'region_loa']\n",
    "cav_data = cav_data[user_attr + rsrc_attr + ['result']]\n",
    "\n",
    "# Change string values to numerical\n",
    "mapping = {'system': 10101, 'human': 10201, 'human and system': 10301} # Control\n",
    "cav_data.control = cav_data.control.replace(mapping)\n",
    "\n",
    "mapping = {'system': 20102, 'human': 20202} # monitoring\n",
    "cav_data.monitoring = cav_data.monitoring.replace(mapping)\n",
    "\n",
    "mapping = {'system': 30103, 'human': 30203} # fallbacj\n",
    "cav_data.fallback = cav_data.fallback.replace(mapping)\n",
    "\n",
    "mapping = {0: 40004, 1: 40104, 2: 40204, 3: 40304, 4: 40404, 5: 40504}\n",
    "cav_data.driving_task_loa = cav_data.driving_task_loa.replace(mapping)\n",
    "\n",
    "mapping = {0: 50005, 1: 50105, 2: 50205, 3: 50305, 4: 50405, 5: 50505}\n",
    "cav_data.vehicle_loa = cav_data.vehicle_loa.replace(mapping)\n",
    "\n",
    "mapping = {0: 60006, 1: 60106, 2: 60206, 3: 60306, 4: 60406, 5: 60506}\n",
    "cav_data.region_loa = cav_data.region_loa.replace(mapping)\n",
    "\n",
    "\n",
    "print(\"# User attr:\", len(user_attr))\n",
    "print(\"# Rsrc attr:\", len(rsrc_attr)); print()\n",
    "\n",
    "# Data statictics:\n",
    "n_users = len(cav_data[user_attr].drop_duplicates())\n",
    "n_rscrc = len(cav_data[rsrc_attr].drop_duplicates())\n",
    "print(\"|U| =\", n_users)\n",
    "print(\"|R| =\", n_rscrc); print()\n",
    "\n",
    "# Add user and resource id columns\n",
    "user_dict = get_user_res(cav_data, user_attr, True)\n",
    "rsrc_dict = get_user_res(cav_data, rsrc_attr, False)\n",
    "cav_data = add_col(cav_data, user_dict, user_attr, \"USRID\")\n",
    "cav_data = add_col(cav_data, rsrc_dict, rsrc_attr, \"RESID\")\n",
    "\n",
    "# Accepted and rejected requests\n",
    "cav_pos = cav_data[cav_data.result == 'approved']\n",
    "cav_neg = cav_data[cav_data.result == 'rejected']\n",
    "print(\"|L+| =\", len(cav_pos), \"{:.2f}%\".format((len(cav_pos) \n",
    "        / len(cav_data) ) * 100))\n",
    "print(\"|L-| =\", len(cav_neg), \"{:.2f}%\".format((len(cav_neg) \n",
    "        / len(cav_data) ) * 100))\n",
    "\n",
    "# Cross validation\n",
    "k = 10\n",
    "test_size = 0.2\n",
    "kfold = StratifiedShuffleSplit(n_splits=k, test_size=test_size, random_state=1)\n",
    "\n",
    "data_partition = kfold.split(cav_data, cav_data.result)\n",
    "data_curpus = [] # A list to storage the k folds\n",
    "\n",
    "for train_data, test_data in data_partition:\n",
    "    X_train, X_test = cav_data.iloc[train_data], cav_data.iloc[test_data]\n",
    "    data_curpus.append([X_train, X_test])\n",
    "\n",
    "print(\"Done!\")  \n",
    "print(\" - k =\", k)\n",
    "print(\" - Train-Test size: \", len(data_curpus[0][0]), \"(\", (1-test_size)*100, \") \\t\", len(data_curpus[0][1]), \"(\", test_size*100, \")\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing\n",
    "1. Continouos to Categorical Values\n",
    "2. Handle missing values - New value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Train access request = 191664 80.00%\n",
      "# Train access request = 47916 80.00%\n",
      "Total = 239580\n",
      "\n",
      "TASK 1: Done!\n",
      "\n",
      "TASK 2: Done!\n",
      "\n",
      "TASK 3: Drop duplicates access requests\n",
      " -TRAIN DATA: Removing 0 positive access requests\n",
      " -TRAIN DATA: Removing 0 negative access requests\n",
      " -TEST DATA: Removing 0 positive access requests\n",
      " -TEST DATA: Removing 0 negative access requests\n",
      "Hecho!\n"
     ]
    }
   ],
   "source": [
    "id_kfold = 1\n",
    "\n",
    "cav_train, cav_test = data_curpus[id_kfold][0], data_curpus[id_kfold][1]\n",
    "print(\"# Train access request =\", len(cav_train), \"{:.2f}%\".format(\n",
    "    len(cav_train)/(len(cav_train)+len(cav_test))*100))\n",
    "print(\"# Train access request =\", len(cav_test), \"{:.2f}%\".format(\n",
    "    len(cav_train)/(len(cav_train)+len(cav_test))*100))\n",
    "print(\"Total =\", len(cav_train)+len(cav_test)); print()\n",
    "\n",
    "#### **** SELECT FUNCTIONAL ATTRIBUTES **** ####\n",
    "cav_train = cav_train[user_attr + rsrc_attr + ['USRID', 'RESID', 'result']]\n",
    "cav_test = cav_test[user_attr + rsrc_attr + ['USRID', 'RESID', 'result']]\n",
    "\n",
    "##### ***** Task 1: Null and uknwokn values ***** #####\n",
    "print(\"TASK 1: Done!\"); print() # NA\n",
    "\n",
    "\n",
    "##### ***** TASK 2: convert continuous values to categorical values ***** #####\n",
    "print(\"TASK 2: Done!\"); print() # NA \n",
    "\n",
    "##### ***** TASK 3: Drop duplicates access requests ***** #####\n",
    "print(\"TASK 3: Drop duplicates access requests\")\n",
    "\n",
    "positive_cav_train = cav_train[cav_train.result=='approved']\n",
    "positive_cav_test = cav_test[cav_test.result=='approved']\n",
    "negative_cav_train = cav_train[cav_train.result=='rejected']\n",
    "negative_cav_test = cav_test[cav_test.result=='rejected']\n",
    "\n",
    "\n",
    "print(\" -TRAIN DATA: Removing\", \n",
    "    len(positive_cav_train.drop_duplicates()) - \n",
    "    len(positive_cav_train), \"positive access requests\")\n",
    "print(\" -TRAIN DATA: Removing\", \n",
    "    len(negative_cav_train.drop_duplicates()) - \n",
    "    len(negative_cav_train), \"negative access requests\")\n",
    "print(\" -TEST DATA: Removing\", \n",
    "    len(positive_cav_test.drop_duplicates()) - \n",
    "    len(positive_cav_test), \"positive access requests\")\n",
    "print(\" -TEST DATA: Removing\", \n",
    "    len(negative_cav_test.drop_duplicates()) - \n",
    "    len(negative_cav_test), \"negative access requests\")\n",
    "\n",
    "# Filter resources\n",
    "#bolean_series = negative_cav_train.RESID.isin(top_list)\n",
    "#negative_cav_train = negative_cav_train[bolean_series]\n",
    "print(\"Hecho!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selection of Learning Algorithm\n",
    "1. K-modes algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready!\n"
     ]
    }
   ],
   "source": [
    "###Select the number of clusters###\n",
    "num_clusters = 15\n",
    "\n",
    "#DO NOT CHANGE THIS CODE\n",
    "# seed = 29\n",
    "\n",
    "#Compute centroids and labels\n",
    "# num_init = 5\n",
    "centroids = []\n",
    "kmodes_huang = kmodes.KModes(n_clusters=num_clusters, init='Huang', verbose=0)\n",
    "cluster_labels = kmodes_huang.fit_predict(positive_cav_train)\n",
    "centroids = kmodes_huang.cluster_centroids_\n",
    "\n",
    "print('Ready!')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/daniel/anaconda3/envs/tesis_env/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "positive_cav_train[\"cls\"] = cluster_labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter tuning\n",
    "1. Number of clusters (Silhouette Method)\n",
    "2. Cluster initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy Rules Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq(value, attribute, dataplace):\n",
    "    \"\"\"\n",
    "    Calculate the frequency of the value in the dataplace.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    value : int\n",
    "        Value to compute its frequency.\n",
    "\n",
    "    attribute : string\n",
    "        Name of the attribute.\n",
    "\n",
    "    dataplace : DataFrame pandas\n",
    "        Data to search.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float [0-1]\n",
    "        Returns the value of frequency of the value in the data.\n",
    "    \"\"\"\n",
    "    value_freq = dataplace[dataplace[attribute] == value].drop_duplicates()\n",
    "    return len(value_freq) / len(dataplace)\n",
    "\n",
    "def freq_rels(attrA, attrB, dataplace):\n",
    "    \"\"\"\n",
    "    Compute the frequency of the attribute relation.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    attrA : string\n",
    "        Name of the attribute A to compare.\n",
    "    attrB : string\n",
    "        Name of the attribute B to compare.\n",
    "    dataplace : DataFrame pandas\n",
    "        Data to search.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float [0-1]\n",
    "        Returns the value of frequency of the range of values in the data.\n",
    "    \"\"\"\n",
    "    # Get the range of values of attribute A.\n",
    "    range_val_A = set(dataplace[attrA].values.tolist())\n",
    "\n",
    "    # Get the range of values of attribute B.\n",
    "    range_val_B = set(dataplace[attrB].values.tolist())\n",
    "\n",
    "    # Check if the len\n",
    "    if len(range_val_A) == len(range_val_B):\n",
    "        # Compute the intersection\n",
    "        inter_A_B = range_val_A.intersection(range_val_B)\n",
    "        if len(inter_A_B) == len(range_val_A):\n",
    "            boolean_series = dataplace[attrA].isin(inter_A_B)\n",
    "            frac_log = dataplace[boolean_series]\n",
    "            return len(frac_log) / len(dataplace) # Return the fraction\n",
    "        return 0\n",
    "    else:\n",
    "        return 0    \n",
    "\n",
    "def extract_attributes_filters(C_i, A, L, posThr, negThr):\n",
    "    \"\"\"\n",
    "    Effective attribute extraction algorithm. Generate a rule for each cluster.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    C_i : DataFrame pandas\n",
    "        Access request in the Cluster i.\n",
    "\n",
    "    A : List\n",
    "        List of attributes.\n",
    "\n",
    "    V : List\n",
    "        Values of attributes.\n",
    "\n",
    "    L : DataFrame\n",
    "        Complete Access Log.\n",
    "\n",
    "    PosThr : float\n",
    "        Positive Threshold to the effective positive attribute.\n",
    "\n",
    "    NegThr : float\n",
    "        Negative Threshold to the effective negative attribute.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        Returns the rule with the effective attributes for the cluster i.\n",
    "    \"\"\"\n",
    "    filter_to_ret = [] # Rule\n",
    "    for a in A:        \n",
    "        a_values = C_i[a].drop_duplicates().tolist()        \n",
    "        for v in a_values:\n",
    "            if freq(v, a, C_i) - freq(v, a, L) > posThr:\n",
    "                if not [a, v] in filter_to_ret:\n",
    "                    filter_to_ret.append([a, v])\n",
    "            if freq(v, a, L) - freq(v, a, C_i) > negThr:\n",
    "                if not [a, -1*v] in filter_to_ret:\n",
    "                    filter_to_ret.append([a, v*-1])\n",
    "    return filter_to_ret\n",
    "\n",
    "def extract_relations(C_i, A, L, posThr, negThr):\n",
    "    \"\"\"\n",
    "    Extract the effective relation. For each cluster.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    C_i : DataFrame pandas\n",
    "        Access request in the Cluster i.\n",
    "\n",
    "    A : List\n",
    "        List of attributes.\n",
    "\n",
    "    L : DataFrame\n",
    "        Complete Access Log.\n",
    "\n",
    "    posThr : float\n",
    "        Positive Threshold to the effective positive relation.\n",
    "\n",
    "    negThr : float\n",
    "        Negative Threshold to the effective negative relation.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        Returns the rule with the effective relation for the cluster i.\n",
    "    \"\"\"\n",
    "    relation_to_ret = []\n",
    "    for a in A:\n",
    "        for b in A:\n",
    "            if a != b:\n",
    "                if freq_rels(a, b, C_i) - freq_rels(a, b, L) > posThr:\n",
    "                    if not [a, b] in relation_to_ret:\n",
    "                        relation_to_ret.append([a, b])\n",
    "                if freq_rels(a, b, L) - freq_rels(a, b, C_i) > negThr:\n",
    "                    if not [a, '!'+b] in relation_to_ret:                        \n",
    "                        relation_to_ret.append([a, '!'+b])\n",
    "                    print()\n",
    "\n",
    "def rule_inference(data_, pos_attr_thr, \n",
    "    neg_attr_thr, pos_rel_thr, neg_rel_thr):\n",
    "    rule_list = [] # All rules\n",
    "    n_cluster = len(data_[\"cls\"].drop_duplicates()) # N clusters\n",
    "    attrs = data_.columns[:-1] # Name of the columns\n",
    "\n",
    "    for C_i in range(n_cluster):\n",
    "        print(C_i)\n",
    "        rule_i = []\n",
    "        data_cluster = data_[data_[\"cls\"] == C_i]\n",
    "        \n",
    "        # Effective attributes\n",
    "        attr_filters = extract_attributes_filters(data_cluster, attrs, data_, \n",
    "            pos_attr_thr, neg_attr_thr)    \n",
    "        rule_i.append(attr_filters)        \n",
    "\n",
    "        # Relations\n",
    "        attr_relation = extract_relations(data_cluster, attrs, data_, \n",
    "            pos_rel_thr, neg_rel_thr)\n",
    "        rule_i.append(attr_relation)\n",
    "        print(rule_i)\n",
    "\n",
    "        rule_list.append([C_i, rule_i])    \n",
    "\n",
    "    return rule_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['monitoring', 'fallback', 'weather', 'visibility', 'traffic_congestion',\n",
       "       'driving_task_loa', 'vehicle_loa', 'region_loa', 'USRID', 'RESID',\n",
       "       'result', 'cls'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = positive_cav_train[positive_cav_train.columns[1:]]\n",
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[[['driving_task_loa', 40004]], None]\n",
      "1\n",
      "[[['driving_task_loa', 40104], ['driving_task_loa', -40004], ['region_loa', 60106]], None]\n",
      "2\n",
      "[[['driving_task_loa', 40204], ['driving_task_loa', -40004], ['vehicle_loa', 50405], ['region_loa', 60506]], None]\n",
      "3\n",
      "[[['driving_task_loa', 40204], ['driving_task_loa', -40004], ['region_loa', 60206]], None]\n",
      "4\n",
      "[[['driving_task_loa', 40204], ['vehicle_loa', 50305], ['region_loa', 60506]], None]\n",
      "5\n",
      "[[['driving_task_loa', 40204], ['driving_task_loa', -40004], ['vehicle_loa', 50305], ['region_loa', 60306]], None]\n",
      "6\n",
      "[[['driving_task_loa', 40004], ['vehicle_loa', 50005]], None]\n",
      "7\n",
      "[[['driving_task_loa', 40004], ['vehicle_loa', 50205]], None]\n",
      "8\n",
      "[[['monitoring', 20102], ['monitoring', -20202], ['driving_task_loa', 40304], ['driving_task_loa', -40004], ['vehicle_loa', 50505], ['region_loa', 60406]], None]\n",
      "9\n",
      "[[['driving_task_loa', 40004], ['vehicle_loa', 50505], ['region_loa', 60106]], None]\n",
      "10\n",
      "[[['driving_task_loa', 40104], ['driving_task_loa', -40004], ['region_loa', 60206]], None]\n",
      "11\n",
      "[[['driving_task_loa', 40104], ['driving_task_loa', -40004], ['region_loa', 60306]], None]\n",
      "12\n",
      "[[['driving_task_loa', 40104], ['driving_task_loa', -40004], ['region_loa', 60406]], None]\n",
      "13\n",
      "[[['driving_task_loa', 40004], ['vehicle_loa', 50105], ['region_loa', 60206]], None]\n",
      "14\n",
      "[[['driving_task_loa', 40104], ['driving_task_loa', -40004], ['vehicle_loa', 50305], ['region_loa', 60206], ['RESID', 180202]], None]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0, [[['driving_task_loa', 40004]], None]],\n",
       " [1,\n",
       "  [[['driving_task_loa', 40104],\n",
       "    ['driving_task_loa', -40004],\n",
       "    ['region_loa', 60106]],\n",
       "   None]],\n",
       " [2,\n",
       "  [[['driving_task_loa', 40204],\n",
       "    ['driving_task_loa', -40004],\n",
       "    ['vehicle_loa', 50405],\n",
       "    ['region_loa', 60506]],\n",
       "   None]],\n",
       " [3,\n",
       "  [[['driving_task_loa', 40204],\n",
       "    ['driving_task_loa', -40004],\n",
       "    ['region_loa', 60206]],\n",
       "   None]],\n",
       " [4,\n",
       "  [[['driving_task_loa', 40204],\n",
       "    ['vehicle_loa', 50305],\n",
       "    ['region_loa', 60506]],\n",
       "   None]],\n",
       " [5,\n",
       "  [[['driving_task_loa', 40204],\n",
       "    ['driving_task_loa', -40004],\n",
       "    ['vehicle_loa', 50305],\n",
       "    ['region_loa', 60306]],\n",
       "   None]],\n",
       " [6, [[['driving_task_loa', 40004], ['vehicle_loa', 50005]], None]],\n",
       " [7, [[['driving_task_loa', 40004], ['vehicle_loa', 50205]], None]],\n",
       " [8,\n",
       "  [[['monitoring', 20102],\n",
       "    ['monitoring', -20202],\n",
       "    ['driving_task_loa', 40304],\n",
       "    ['driving_task_loa', -40004],\n",
       "    ['vehicle_loa', 50505],\n",
       "    ['region_loa', 60406]],\n",
       "   None]],\n",
       " [9,\n",
       "  [[['driving_task_loa', 40004],\n",
       "    ['vehicle_loa', 50505],\n",
       "    ['region_loa', 60106]],\n",
       "   None]],\n",
       " [10,\n",
       "  [[['driving_task_loa', 40104],\n",
       "    ['driving_task_loa', -40004],\n",
       "    ['region_loa', 60206]],\n",
       "   None]],\n",
       " [11,\n",
       "  [[['driving_task_loa', 40104],\n",
       "    ['driving_task_loa', -40004],\n",
       "    ['region_loa', 60306]],\n",
       "   None]],\n",
       " [12,\n",
       "  [[['driving_task_loa', 40104],\n",
       "    ['driving_task_loa', -40004],\n",
       "    ['region_loa', 60406]],\n",
       "   None]],\n",
       " [13,\n",
       "  [[['driving_task_loa', 40004],\n",
       "    ['vehicle_loa', 50105],\n",
       "    ['region_loa', 60206]],\n",
       "   None]],\n",
       " [14,\n",
       "  [[['driving_task_loa', 40104],\n",
       "    ['driving_task_loa', -40004],\n",
       "    ['vehicle_loa', 50305],\n",
       "    ['region_loa', 60206],\n",
       "    ['RESID', 180202]],\n",
       "   None]]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_attr_thr = 0.3\n",
    "neg_attr_thr = 0.3\n",
    "pos_rel_thr = 0.2\n",
    "neg_rel_thr = 0.2\n",
    "test = rule_inference(df_test, pos_attr_thr, neg_attr_thr, pos_rel_thr, neg_attr_thr)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['driving_task_loa', 40004]],\n",
       " [['driving_task_loa', 40104],\n",
       "  ['driving_task_loa', -40004],\n",
       "  ['region_loa', 60106]],\n",
       " [['driving_task_loa', 40204],\n",
       "  ['driving_task_loa', -40004],\n",
       "  ['vehicle_loa', 50405],\n",
       "  ['region_loa', 60506]],\n",
       " [['driving_task_loa', 40204],\n",
       "  ['driving_task_loa', -40004],\n",
       "  ['region_loa', 60206]],\n",
       " [['driving_task_loa', 40204], ['vehicle_loa', 50305], ['region_loa', 60506]],\n",
       " [['driving_task_loa', 40204],\n",
       "  ['driving_task_loa', -40004],\n",
       "  ['vehicle_loa', 50305],\n",
       "  ['region_loa', 60306]],\n",
       " [['driving_task_loa', 40004], ['vehicle_loa', 50005]],\n",
       " [['driving_task_loa', 40004], ['vehicle_loa', 50205]],\n",
       " [['monitoring', 20102],\n",
       "  ['monitoring', -20202],\n",
       "  ['driving_task_loa', 40304],\n",
       "  ['driving_task_loa', -40004],\n",
       "  ['vehicle_loa', 50505],\n",
       "  ['region_loa', 60406]],\n",
       " [['driving_task_loa', 40004], ['vehicle_loa', 50505], ['region_loa', 60106]],\n",
       " [['driving_task_loa', 40104],\n",
       "  ['driving_task_loa', -40004],\n",
       "  ['region_loa', 60206]],\n",
       " [['driving_task_loa', 40104],\n",
       "  ['driving_task_loa', -40004],\n",
       "  ['region_loa', 60306]],\n",
       " [['driving_task_loa', 40104],\n",
       "  ['driving_task_loa', -40004],\n",
       "  ['region_loa', 60406]],\n",
       " [['driving_task_loa', 40004], ['vehicle_loa', 50105], ['region_loa', 60206]],\n",
       " [['driving_task_loa', 40104],\n",
       "  ['driving_task_loa', -40004],\n",
       "  ['vehicle_loa', 50305],\n",
       "  ['region_loa', 60206],\n",
       "  ['RESID', 180202]]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_rules = []\n",
    "for rule in test:\n",
    "    only_rules.append(rule[1][0])\n",
    "only_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ROLE_ROLLUP_2', 118343], ['ROLE_FAMILY', 118424]]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_rules[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_neg  = []\n",
    "for i,row in positive_cav_train.iterrows():\n",
    "    \n",
    "    # Evaluación\n",
    "    denies_count = 0    \n",
    "    for rule in only_rules:                                      \n",
    "        # En esta parte se evalua la regla completa\n",
    "        res = True\n",
    "        \n",
    "        #for idx_r, attr_val in enumerate(rule):\n",
    "        for attr_val in rule:            \n",
    "            if attr_val[1] < 0:\n",
    "                if row[attr_val[0]] != attr_val[1]*-1:\n",
    "                    res = False\n",
    "                    break\n",
    "            else:\n",
    "                if row[attr_val[0]] != attr_val[1]:\n",
    "                    res = False\n",
    "                    break\n",
    "        if res == False:\n",
    "            denies_count += 1\n",
    "    \n",
    "    if denies_count == len(only_rules):\n",
    "        false_neg.append(row)\n",
    "        #print(\"FP-2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa FN: 58.65\n",
      "FN:  55823  de  95180\n"
     ]
    }
   ],
   "source": [
    "FN = len(false_neg)\n",
    "print(\"Tasa FN: {:.2f}\".format((FN/ len(positive_cav_train))*100))\n",
    "print(\"FN: \", FN, \" de \", len(positive_cav_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_pos  = []\n",
    "for i,row in negative_cav_test.iterrows():\n",
    "    # Evaluación\n",
    "    denies_count = 0\n",
    "    temp_rules_n = 0\n",
    "    print(row)\n",
    "    for rule in only_rules:                                      \n",
    "        # En esta parte se evalua la regla completa\n",
    "        res = True\n",
    "        #print(rule)                     \n",
    "        for attr_val in rule:\n",
    "            if attr_val[1] < 0:\n",
    "                #print(attr_val)\n",
    "                if row[attr_val[0]] != attr_val[1]*-1:\n",
    "                    res = False\n",
    "                    break\n",
    "            else:\n",
    "                if row[attr_val[0]] != attr_val[1]:\n",
    "                    res = False\n",
    "                    break\n",
    "        if res == False:\n",
    "            denies_count += 1                                \n",
    "    #print(\"XXX-\", denies_count, temp_rules_n, res)\n",
    "    #print(\"R\", denies_count, len(only_rules))\n",
    "    if denies_count < len(only_rules):\n",
    "        false_pos.append(row)\n",
    "        #print(\"FP-2\")    \n",
    "    #else:\n",
    "        #print(\"ENtra PAPA\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa FP: 0.00\n",
      "FN:  0  de  24121\n"
     ]
    }
   ],
   "source": [
    "FP = len(false_pos)\n",
    "print(\"Tasa FP: {:.2f}\".format((FP/ len(negative_cav_test))*100))\n",
    "print(\"FN: \", FP, \" de \", len(negative_cav_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>control</th>\n",
       "      <th>monitoring</th>\n",
       "      <th>fallback</th>\n",
       "      <th>weather</th>\n",
       "      <th>visibility</th>\n",
       "      <th>traffic_congestion</th>\n",
       "      <th>driving_task_loa</th>\n",
       "      <th>vehicle_loa</th>\n",
       "      <th>region_loa</th>\n",
       "      <th>USRID</th>\n",
       "      <th>RESID</th>\n",
       "      <th>result</th>\n",
       "      <th>cls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13642</th>\n",
       "      <td>10101</td>\n",
       "      <td>20202</td>\n",
       "      <td>30203</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40204</td>\n",
       "      <td>50405</td>\n",
       "      <td>60406</td>\n",
       "      <td>332101</td>\n",
       "      <td>14202</td>\n",
       "      <td>approved</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191106</th>\n",
       "      <td>10201</td>\n",
       "      <td>20202</td>\n",
       "      <td>30203</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>40004</td>\n",
       "      <td>50205</td>\n",
       "      <td>60106</td>\n",
       "      <td>4766101</td>\n",
       "      <td>169202</td>\n",
       "      <td>approved</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177980</th>\n",
       "      <td>10301</td>\n",
       "      <td>20202</td>\n",
       "      <td>30203</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>40104</td>\n",
       "      <td>50405</td>\n",
       "      <td>60106</td>\n",
       "      <td>4950101</td>\n",
       "      <td>156202</td>\n",
       "      <td>approved</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25174</th>\n",
       "      <td>10101</td>\n",
       "      <td>20102</td>\n",
       "      <td>30103</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>40404</td>\n",
       "      <td>50505</td>\n",
       "      <td>60406</td>\n",
       "      <td>5209101</td>\n",
       "      <td>22202</td>\n",
       "      <td>approved</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55388</th>\n",
       "      <td>10101</td>\n",
       "      <td>20102</td>\n",
       "      <td>30203</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>40304</td>\n",
       "      <td>50405</td>\n",
       "      <td>60306</td>\n",
       "      <td>2148101</td>\n",
       "      <td>51202</td>\n",
       "      <td>approved</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41641</th>\n",
       "      <td>10201</td>\n",
       "      <td>20202</td>\n",
       "      <td>30203</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>40004</td>\n",
       "      <td>50305</td>\n",
       "      <td>60306</td>\n",
       "      <td>1711101</td>\n",
       "      <td>37202</td>\n",
       "      <td>approved</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65698</th>\n",
       "      <td>10101</td>\n",
       "      <td>20102</td>\n",
       "      <td>30203</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>40304</td>\n",
       "      <td>50505</td>\n",
       "      <td>60306</td>\n",
       "      <td>5803101</td>\n",
       "      <td>57202</td>\n",
       "      <td>approved</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79531</th>\n",
       "      <td>10201</td>\n",
       "      <td>20202</td>\n",
       "      <td>30203</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>40004</td>\n",
       "      <td>50105</td>\n",
       "      <td>60306</td>\n",
       "      <td>6326101</td>\n",
       "      <td>67202</td>\n",
       "      <td>approved</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110641</th>\n",
       "      <td>10201</td>\n",
       "      <td>20202</td>\n",
       "      <td>30203</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>40004</td>\n",
       "      <td>50205</td>\n",
       "      <td>60006</td>\n",
       "      <td>4161101</td>\n",
       "      <td>97202</td>\n",
       "      <td>approved</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218985</th>\n",
       "      <td>10301</td>\n",
       "      <td>20202</td>\n",
       "      <td>30203</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>40104</td>\n",
       "      <td>50405</td>\n",
       "      <td>60206</td>\n",
       "      <td>6025101</td>\n",
       "      <td>192202</td>\n",
       "      <td>approved</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95180 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        control  monitoring  fallback  weather  visibility  \\\n",
       "13642     10101       20202     30203        6           0   \n",
       "191106    10201       20202     30203        9           7   \n",
       "177980    10301       20202     30203        2           0   \n",
       "25174     10101       20102     30103        6           7   \n",
       "55388     10101       20102     30203        6           0   \n",
       "...         ...         ...       ...      ...         ...   \n",
       "41641     10201       20202     30203        9           1   \n",
       "65698     10101       20102     30203        6           5   \n",
       "79531     10201       20202     30203        5           0   \n",
       "110641    10201       20202     30203        9           7   \n",
       "218985    10301       20202     30203       10           6   \n",
       "\n",
       "        traffic_congestion  driving_task_loa  vehicle_loa  region_loa  \\\n",
       "13642                    0             40204        50405       60406   \n",
       "191106                   7             40004        50205       60106   \n",
       "177980                   8             40104        50405       60106   \n",
       "25174                    8             40404        50505       60406   \n",
       "55388                    3             40304        50405       60306   \n",
       "...                    ...               ...          ...         ...   \n",
       "41641                    2             40004        50305       60306   \n",
       "65698                    9             40304        50505       60306   \n",
       "79531                   10             40004        50105       60306   \n",
       "110641                   6             40004        50205       60006   \n",
       "218985                   9             40104        50405       60206   \n",
       "\n",
       "          USRID   RESID    result  cls  \n",
       "13642    332101   14202  approved    2  \n",
       "191106  4766101  169202  approved    6  \n",
       "177980  4950101  156202  approved    1  \n",
       "25174   5209101   22202  approved    8  \n",
       "55388   2148101   51202  approved    2  \n",
       "...         ...     ...       ...  ...  \n",
       "41641   1711101   37202  approved    6  \n",
       "65698   5803101   57202  approved    5  \n",
       "79531   6326101   67202  approved    6  \n",
       "110641  4161101   97202  approved    6  \n",
       "218985  6025101  192202  approved   10  \n",
       "\n",
       "[95180 rows x 13 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_cav_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FN: 55823  - 58.65\n",
      "FP: 0  - 0.00\n",
      "Precision: 1.0\n",
      "Recall: 0.41350073544862365\n",
      "F-score 0.5850732512245701\n",
      "# Rules: 15\n",
      "WSC: 48\n"
     ]
    }
   ],
   "source": [
    "\n",
    "TP = len(positive_cav_train) - FN\n",
    "#TP = 50 - FN\n",
    "TN = len(negative_cav_train) - FP\n",
    "#TN = 50 - FP\n",
    "\n",
    "precision = TP / (TP + FP)\n",
    "\n",
    "recall = TP / (TP + FN)\n",
    "\n",
    "fscore = 2*(precision*recall)/(precision+recall)\n",
    "\n",
    "print(\"FN:\", FN, \" - {:.2f}\".format((FN/len(positive_cav_train))*100))\n",
    "#print(\"FN:\", FN, \" - {:.2f}\".format((FN/50)*100))\n",
    "print(\"FP:\", FP, \" - {:.2f}\".format((FP/len(negative_cav_train))*100))\n",
    "#print(\"FP:\", FP, \" - {:.2f}\".format((FP/50)*100))\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F-score\", fscore)\n",
    "\n",
    "def compute_wsc(policy):\n",
    "    return sum([len(rule) for rule in policy])\n",
    "\n",
    "print(\"# Rules:\", len(only_rules))\n",
    "print(\"WSC:\", compute_wsc(only_rules))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WSC: 59\n",
      "Precision: 0.9584454409566517\n",
      "Recall: 0.3115444415651723\n",
      "F-score: 0.47023736768768176\n"
     ]
    }
   ],
   "source": [
    "###Select the threshold###\n",
    "threshold = 0.25\n",
    "\n",
    "#DO NOT CHANGE THIS CODE\n",
    "policy = pm.create_policy(pos_entries, cluster_labels, centroids, num_clusters, threshold)\n",
    "\n",
    "print('WSC:', pm.compute_wsc(policy))\n",
    "false_negs,_,precision,recall,fscore = pm.evaluate_policy(policy, pos_entries, neg_entries)\n",
    "print('Precision:',precision)\n",
    "print('Recall:',recall)\n",
    "print('F-score:',fscore)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy Enhancement\n",
    "1. Rule Pruning\n",
    "2. Policy Refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "deec884ae07beaa7e970d39d84b9343805b80aeba4e343861fb4097b62dc7004"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
