{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b73e9947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph as ig\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from time import time\n",
    "import math\n",
    "import powerlaw\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import nx_cugraph as nxcg\n",
    "from sklearn.manifold import TSNE\n",
    "from auxiliar_bb import noise_corrected, disparity\n",
    "from auxiliar_projections_large import apply_projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c92a0cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILENAME = \"/home/daniel/Documents/phd/phd-thesis-lab/12-third_year/00-Data/05-actor-movie/actor-movie.graphml\"\n",
    "PROJ_NAME = [\"simple\", \"jaccard\", \"master\", \"hyper\", \"resall\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46cb5b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IGRAPH UN-T 511463 1470404 -- \n",
      "+ attr: id (v), name (v), type (v)\n",
      "\n",
      "The graph IS bipartite\n",
      "|U|= 383640  \t|R|= 127823  \t|U|+|R|= 511463 = 511463\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###### ****** Read BI GRAPH ****** ######\n",
    "g = ig.read(FILENAME)\n",
    "print(g.summary())\n",
    "print()\n",
    "\n",
    "user_nodes = g.vs.select(type=0)\n",
    "res_nodes = g.vs.select(type=1)\n",
    "\n",
    "if(g.is_bipartite()): # Check if the the graph is bipartite\n",
    "    print(\"The graph IS bipartite\")\n",
    "else:\n",
    "    print(\"The graph IS NOT bipartite\")\n",
    "    exit()\n",
    "print(\"|U|=\",len(user_nodes), \" \\t|R|=\",len(res_nodes), \" \\t|U|+|R|=\",\n",
    "      len(user_nodes)+len(res_nodes), \"=\", g.vcount())\n",
    "print()\n",
    "###### ****** END ****** ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b46d437d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def escalar_pesos(grafo):\n",
    "    \"\"\"Función para escalar los pesos.\"\"\"\n",
    "    ### Factor de Escalado\n",
    "    edges_temp = grafo.es[\"weight\"]\n",
    "    print(f\"Peso máximo={max(edges_temp)} y mínimo={min(edges_temp)} en aristas: \")\n",
    "    print()\n",
    "\n",
    "    ### Determinar si el peso minimo es 0\n",
    "    if min(edges_temp) == 0.0:\n",
    "        # Se obtiene el minimu segundo\n",
    "        min_val = sorted(set(grafo.es[\"weight\"]))[1]\n",
    "        factor_escala = math.ceil(1 / min_val)\n",
    "        print(\"Factor de escala:\", factor_escala)\n",
    "\n",
    "    else:\n",
    "        factor_escala = math.ceil(1 / min(edges_temp))\n",
    "        print(\"Factor de escala:\", factor_escala)\n",
    "    \n",
    "    grafo.es[\"weight\"] = (np.array(edges_temp) * factor_escala).round().astype(int)\n",
    "    for edge in grafo.es:\n",
    "        if edge[\"weight\"] == 0:\n",
    "            edge[\"weight\"] = 1\n",
    "    \n",
    "    return grafo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8f9fd54",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m proj_opcion \u001b[38;5;129;01min\u001b[39;00m PROJ_NAME:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m###### ****** Projections ****** ######\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     user_graph \u001b[38;5;241m=\u001b[39m \u001b[43mapply_projection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproj_opcion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43muser_nodes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# False = Users = 0\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone PROJ1 - Users Projection\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m     edges_temp \u001b[38;5;241m=\u001b[39m user_graph\u001b[38;5;241m.\u001b[39mes()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/phd/phd-thesis-lab/13-paper-modelling/auxiliar_projections_large.py:848\u001b[0m, in \u001b[0;36mapply_projection\u001b[0;34m(bigraph, projection_name, usr_size, typenn)\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    833\u001b[0m \u001b[38;5;124;03mApply the function based on the name of projection\u001b[39;00m\n\u001b[1;32m    834\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    845\u001b[0m \n\u001b[1;32m    846\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    847\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m projection_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msimple\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 848\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msimple_projection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbigraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypen\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtypenn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m projection_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweights\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    850\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m weights_projection(bigraph, usr_size, typen\u001b[38;5;241m=\u001b[39mtypenn)\n",
      "File \u001b[0;32m~/Documents/phd/phd-thesis-lab/13-paper-modelling/auxiliar_projections_large.py:30\u001b[0m, in \u001b[0;36msimple_projection\u001b[0;34m(bigraph, typen)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bigraph\u001b[38;5;241m.\u001b[39mbipartite_projection(which\u001b[38;5;241m=\u001b[39mtypen)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbigraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbipartite_projection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwhich\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtypen\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tesis/lib/python3.10/site-packages/igraph/__init__.py:3637\u001b[0m, in \u001b[0;36mGraph.bipartite_projection\u001b[0;34m(self, types, multiplicity, probe1, which)\u001b[0m\n\u001b[1;32m   3635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m multiplicity:\n\u001b[1;32m   3636\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m which \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 3637\u001b[0m         g1, w1 \u001b[38;5;241m=\u001b[39m \u001b[43msuperclass_meth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprobe1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhich\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3638\u001b[0m         g2, w2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3639\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m which \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/tesis/lib/python3.10/site-packages/igraph/__init__.py:237\u001b[0m, in \u001b[0;36mGraph.__init__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    234\u001b[0m shortest_paths_dijkstra \u001b[38;5;241m=\u001b[39m GraphBase\u001b[38;5;241m.\u001b[39mshortest_paths\n\u001b[1;32m    235\u001b[0m subgraph \u001b[38;5;241m=\u001b[39m GraphBase\u001b[38;5;241m.\u001b[39minduced_subgraph\n\u001b[0;32m--> 237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m    238\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"__init__(n=0, edges=None, directed=False, graph_attrs=None,\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;124;03m    vertex_attrs=None, edge_attrs=None)\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;124;03m      M{m} is the number of edges.\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;66;03m# Pop the special __ptr keyword argument\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for proj_opcion in PROJ_NAME:\n",
    "    ###### ****** Projections ****** ######\n",
    "    user_graph = apply_projection(g, proj_opcion,\n",
    "                                len(user_nodes), False) # False = Users = 0\n",
    "    print(\"Done PROJ1 - Users Projection\")\n",
    "    edges_temp = user_graph.es()[\"weight\"]\n",
    "    print(f\"Peso máximo={max(edges_temp)} y mínimo={min(edges_temp)} en aristas: \")\n",
    "\n",
    "    rsrs_graph = apply_projection(g, proj_opcion,\n",
    "                                len(user_nodes), True) # True = Resources = 1\n",
    "    print(\"\\nDone PROJ2 - Resources Projection\")\n",
    "    edges_temp = rsrs_graph.es()[\"weight\"]\n",
    "    print(f\"Peso máximo={max(edges_temp)} y mínimo={min(edges_temp)} en aristas: \")\n",
    "    print()\n",
    "\n",
    "    ###### ****** BACKBONING RESOURCES ****** ######\n",
    "    g_toy = user_graph.copy() # Graph to analyze\n",
    "    print(\"\\n##### **** BACKBONING USERS **** #####\")\n",
    "    print(\"Projection Name:\", proj_opcion)\n",
    "    print(\"Summary\\n\",g_toy.summary())\n",
    "    print(\"##### END #####\")\n",
    "    print()\n",
    "\n",
    "    g_toy = escalar_pesos(g_toy)\n",
    "    print(f\"Peso máximo={max(g_toy.es['weight'])} y mínimo={min(g_toy.es['weight'])} en aristas: \")\n",
    "    print()\n",
    "\n",
    "    ### Disparity filter ###\n",
    "    a = time()\n",
    "    bb_df = disparity(g_toy)\n",
    "    b = time() - a\n",
    "    print(\"BOT DF - time: %.10f seconds.\" % b)\n",
    "    for alpha__, g__ in bb_df.items():\n",
    "        print(f\"Grafo filtrado con alpha={alpha__}: {g__.summary()}\")\n",
    "        flname = (\n",
    "            \"am/top/amz_top_\" + proj_opcion + \"_DF_alpha\" + str(alpha__)[2:] + \".graphml\"\n",
    "        )\n",
    "        g__.write_graphml(flname)\n",
    "    print(\"================================\")\n",
    "\n",
    "    # Noise Corrected\n",
    "    a = time()\n",
    "    bb_nc = noise_corrected(g_toy)\n",
    "    b = time() - a\n",
    "    print(\"BOT NC - time: %.10f seconds.\" % b)\n",
    "    for alpha__, g__ in bb_nc.items():\n",
    "        print(f\"Grafo filtrado con alpha={alpha__}: {g__.summary()}\")\n",
    "        flname = (\n",
    "            \"am/top/amz_top_\" + proj_opcion + \"_NC_alpha\" + str(alpha__)[2:] + \".graphml\"\n",
    "        )\n",
    "        g__.write_graphml(flname)\n",
    "    print(\"================================\")\n",
    "    print()\n",
    "    print(\"##### ***** Done RSCS ***** #####\")\n",
    "    ###### ****** END ****** ######\n",
    "\n",
    "\n",
    "\n",
    "    g_toy = rsrs_graph.copy() # Graph to analyze\n",
    "    print(\"\\n##### **** BACKBONING USERS **** #####\")\n",
    "    print(\"Projection Name:\", proj_opcion)\n",
    "    print(\"Summary\\n\",g_toy.summary())\n",
    "    print(\"##### END #####\")\n",
    "    print()\n",
    "\n",
    "    g_toy = escalar_pesos(g_toy)\n",
    "    print(f\"Peso máximo={max(g_toy.es['weight'])} y mínimo={min(g_toy.es['weight'])} en aristas: \")\n",
    "    print()\n",
    "\n",
    "    ### Disparity filter ###\n",
    "    a = time()\n",
    "    bb_df = disparity(g_toy)\n",
    "    b = time() - a\n",
    "    print(\"BOT DF - time: %.10f seconds.\" % b)\n",
    "    for alpha__, g__ in bb_df.items():\n",
    "        print(f\"Grafo filtrado con alpha={alpha__}: {g__.summary()}\")\n",
    "        flname = (\n",
    "            \"am/bot/amz_bot_\" + proj_opcion + \"_DF_alpha\" + str(alpha__)[2:] + \".graphml\"\n",
    "        )\n",
    "        g__.write_graphml(flname)\n",
    "    print(\"================================\")\n",
    "\n",
    "    # Noise Corrected\n",
    "    a = time()\n",
    "    bb_nc = noise_corrected(g_toy)\n",
    "    b = time() - a\n",
    "    print(\"BOT NC - time: %.10f seconds.\" % b)\n",
    "    for alpha__, g__ in bb_nc.items():\n",
    "        print(f\"Grafo filtrado con alpha={alpha__}: {g__.summary()}\")\n",
    "        flname = (\n",
    "            \"am/bot/amz_bot_\" + proj_opcion + \"_NC_alpha\" + str(alpha__)[2:] + \".graphml\"\n",
    "        )\n",
    "        g__.write_graphml(flname)\n",
    "    print(\"================================\")\n",
    "    print()\n",
    "    print(\"##### ***** Done RSCS ***** #####\")\n",
    "    ###### ****** END ****** ######\n",
    "\n",
    "    ###### ****** END ****** ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd388409",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rsrs_graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m###### ****** BACKBONING RESOURCES ****** ######\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m g_toy \u001b[38;5;241m=\u001b[39m \u001b[43mrsrs_graph\u001b[49m\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;66;03m# Graph to analyze\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m##### **** BACKBONING USERS **** #####\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProjection Name:\u001b[39m\u001b[38;5;124m\"\u001b[39m, PROJ_NAME)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rsrs_graph' is not defined"
     ]
    }
   ],
   "source": [
    "###### ****** BACKBONING RESOURCES ****** ######\n",
    "g_toy = rsrs_graph.copy() # Graph to analyze\n",
    "print(\"\\n##### **** BACKBONING USERS **** #####\")\n",
    "print(\"Projection Name:\", PROJ_NAME)\n",
    "print(\"Summary\\n\",g_toy.summary())\n",
    "print(\"##### END #####\n",
    "print()\n",
    "\n",
    "g_toy = escalar_pesos(g_toy)\n",
    "print(f\"Peso máximo={max(g_toy.es['weight'])} y mínimo={min(g_toy.es['weight'])} en aristas: \")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ab4fc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bipartite_cc_uu_prime(graph, u_id, u_prime_id):\n",
    "    \"\"\"\n",
    "    Calculates the Jaccard index based clustering coefficient for a pair of vertices\n",
    "    u and u' from the same set of nodes in a bipartite graph.\n",
    "\n",
    "    Args:\n",
    "        graph: An igraph Graph object. Must be bipartite with a 'type' vertex attribute.\n",
    "        u_id: The ID of the first vertex.\n",
    "        u_prime_id: The ID of the second vertex.\n",
    "\n",
    "    Returns:\n",
    "        The Jaccard index (cc_u_u_prime) or 0 if union of neighbors is empty.\n",
    "    \"\"\"\n",
    "    if not graph.is_bipartite():\n",
    "        raise ValueError(\"Graph must be bipartite.\")\n",
    "\n",
    "    # Get neighbors of u and u'\n",
    "    neighbors_u = set(graph.neighbors(u_id))\n",
    "    neighbors_u_prime = set(graph.neighbors(u_prime_id))\n",
    "\n",
    "    # Calculate intersection and union\n",
    "    intersection = len(neighbors_u.intersection(neighbors_u_prime))\n",
    "    union = len(neighbors_u.union(neighbors_u_prime))\n",
    "\n",
    "    if union == 0:\n",
    "        return 0.0\n",
    "    return intersection / union\n",
    " \n",
    "def local_bipartite_clustering_coefficient(graph, u_id, U_type_value=False):\n",
    "    \"\"\"\n",
    "    Calculates the local clustering coefficient for a vertex u in a bipartite graph.\n",
    "    The formula uses neighbors of neighbors (N(N(u))) that are of the same type as u.\n",
    "\n",
    "    Args:\n",
    "        graph: An igraph Graph object. Must be bipartite with a 'type' vertex attribute\n",
    "               (e.g., True/False or 0/1 for the two partitions).\n",
    "        u_id: The ID of the vertex for which to calculate the local clustering coefficient.\n",
    "        U_type_value: The boolean value (True/False) that indicates the partition\n",
    "                      to which node u belongs. All nodes in U should have this type.\n",
    "\n",
    "    Returns:\n",
    "        The local clustering coefficient for vertex u, or 0 if N(N(u)) is empty.\n",
    "    \"\"\"\n",
    "    if not graph.is_bipartite():\n",
    "        raise ValueError(\"Graph must be bipartite.\")\n",
    "    if \"type\" not in graph.vs.attributes():\n",
    "        raise ValueError(\"Bipartite graph must have a 'type' vertex attribute.\")\n",
    "\n",
    "    # Ensure u_id is of the specified U_type_value\n",
    "    if graph.vs[u_id][\"type\"] != U_type_value:\n",
    "        raise ValueError(f\"Vertex {u_id} does not belong to the specified partition U.\")\n",
    "\n",
    "    # Get neighbors of u\n",
    "    neighbors_u = graph.neighbors(u_id)\n",
    "    \n",
    "    # Get neighbors of neighbors of u, filtering for nodes of the same type as u\n",
    "    # These are the u' nodes in N(N(u)) that are in the same partition U\n",
    "    nn_u = set()\n",
    "    for v_neighbor_id in neighbors_u:\n",
    "        for nn_id in graph.neighbors(v_neighbor_id):\n",
    "            if graph.vs[nn_id][\"type\"] == U_type_value and nn_id != u_id: # Exclude u itself\n",
    "                nn_u.add(nn_id)\n",
    "\n",
    "    if not nn_u:\n",
    "        return 0.0\n",
    "\n",
    "    sum_cc_uu_prime = 0.0\n",
    "    for u_prime_id in nn_u:\n",
    "        sum_cc_uu_prime += bipartite_cc_uu_prime(graph, u_id, u_prime_id)\n",
    "\n",
    "    return sum_cc_uu_prime / len(nn_u)\n",
    "\n",
    "def average_local_bipartite_clustering_coefficient(graph, U_type_value=False):\n",
    "    \"\"\"\n",
    "    Calculates the average local clustering coefficient for a set of nodes U\n",
    "    in a bipartite graph.\n",
    "\n",
    "    Args:\n",
    "        graph: An igraph Graph object. Must be bipartite with a 'type' vertex attribute.\n",
    "        U_type_value: The boolean value (True/False) that indicates the partition\n",
    "                      for which to calculate the average clustering coefficient.\n",
    "\n",
    "    Returns:\n",
    "        The average local clustering coefficient for the set U.\n",
    "    \"\"\"\n",
    "    if not graph.is_bipartite():\n",
    "        raise ValueError(\"Graph must be bipartite.\")\n",
    "    if \"type\" not in graph.vs.attributes():\n",
    "        raise ValueError(\"Bipartite graph must have a 'type' vertex attribute.\")\n",
    "\n",
    "    # Get all vertices in set U\n",
    "    U_vertices_ids = [v.index for v in graph.vs if v[\"type\"] == U_type_value]\n",
    "\n",
    "    if not U_vertices_ids:\n",
    "        return 0.0\n",
    "\n",
    "    sum_cc_u = 0.0\n",
    "    for u_id in U_vertices_ids:\n",
    "        sum_cc_u += local_bipartite_clustering_coefficient(graph, u_id, U_type_value)\n",
    "\n",
    "    return sum_cc_u / len(U_vertices_ids)\n",
    "\n",
    "def compute_power_law_bipartite(gb, type_n=1):\n",
    "    \"\"\"Calcula el alpha del bipartita\"\"\"\n",
    "    fit = powerlaw.Fit(gb.degree(gb.vs.select(type=type_n)), discrete=True, verbose=False)\n",
    "    return fit.alpha\n",
    "\n",
    "def compute_power_law(g):\n",
    "    \"\"\"Calcula el alpha del proyectado\"\"\"\n",
    "    fit = powerlaw.Fit(g.degree(), discrete=True, verbose=False)\n",
    "    return fit.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360b26c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_avg_path_length(g, k):\n",
    "    G = g.to_networkx()\n",
    "    nxG = nxcg.from_networkx(G)\n",
    "    all_nodes = list(G.nodes())\n",
    "    sample_nodes = random.sample(all_nodes, k)\n",
    "    total_distances = 0\n",
    "    reachable_pairs = 0\n",
    "    for i, src_node in enumerate(sample_nodes):\n",
    "        sssp_df = nxcg.shortest_path_length(nxG, source=src_node)\n",
    "        total_distances += sum(sssp_df.values())\n",
    "        reachable_pairs += len(sssp_df.values())\n",
    "\n",
    "    apl_approx = float(total_distances) / reachable_pairs\n",
    "    return apl_approx\n",
    "\n",
    "\n",
    "\n",
    "def compute_bip_metrics(gb, typen):\n",
    "    \"\"\"Calcula x1,x2,x3,x8,x9,γ_Ub del grafo bipartito.\"\"\"\n",
    "    x1 = len(gb.vs.select(type=0))\n",
    "    x2 = len(gb.vs.select(type=1))\n",
    "    x3 = gb.ecount()\n",
    "    #x8 = average_local_bipartite_clustering_coefficient(gb, U_type_value=typen)    \n",
    "    x8 = 0.25\n",
    "    x9 = compute_avg_path_length(gb, 100)\n",
    "    #try:\n",
    "    #    x9 = compute_avg_path_length(gb, 100)\n",
    "    #except:\n",
    "    #    x9 = np.inf\n",
    "    x11 = compute_power_law_bipartite(gb, typen)\n",
    "    return dict(x1=x1, x2=x2, x3=x3, x8=x8, x9=x9, x11=x11)\n",
    "\n",
    "def compute_proj_metrics(gu):\n",
    "    \"\"\"Calcula x4,x5,x6,x7,x10,γ_U de la proyección.\"\"\"\n",
    "    x4 = gu.vcount()\n",
    "    x5 = gu.ecount()\n",
    "    x6 = len(gu.connected_components(mode='weak'))\n",
    "    x7 = gu.transitivity_undirected(mode=\"zero\")\n",
    "    x10 = np.inf\n",
    "    #try:\n",
    "    #    x10 = gu.average_path_length(directed=False)\n",
    "    #except:\n",
    "    #    x10 = np.inf\n",
    "    x12 = compute_power_law(gu)\n",
    "    return dict(x4=x4, x5=x5, x6=x6, x7=x7, x10=x10, x12=x12)\n",
    "\n",
    "def evaluate_solution(bip, proj, typen):\n",
    "    \"\"\"Dado bip y proj metrics, arma x, f, g.\"\"\"\n",
    "    # unimos diccionarios\n",
    "    x = {\n",
    "        **bip,\n",
    "        **proj\n",
    "    }\n",
    "    # objetivos\n",
    "    f = np.array([\n",
    "        abs(x[\"x1\"] - x[\"x4\"]) if typen==0 else abs(x[\"x2\"] - x[\"x4\"]),\n",
    "        (2*x[\"x5\"]) / (x[\"x4\"]*(x[\"x4\"]-1)) if x[\"x4\"]>1 else np.inf,\n",
    "        x[\"x6\"],\n",
    "        1 - x[\"x7\"],\n",
    "        abs(x[\"x11\"] - x[\"x12\"]),\n",
    "        abs(x[\"x9\"] - x[\"x10\"]),\n",
    "    ])\n",
    "    # restricciones g_i(x)<=0\n",
    "    #g = np.array([\n",
    "    #    f[1] - x[\"x3\"]/(x[\"x1\"]*x[\"x2\"]) if x[\"x1\"]*x[\"x2\"]>0 else np.inf,\n",
    "    #])\n",
    "    #return dict(metrics=x, f=f, g=g, graph=proj)\n",
    "    return dict(metrics=x, f=f, graph=proj)\n",
    "\n",
    "def is_feasible(sol):\n",
    "    return np.all(sol[\"g\"] <= 0)\n",
    "\n",
    "def pareto_front(sols):\n",
    "    front = []\n",
    "    for i, si in enumerate(sols):\n",
    "        if any(np.all(sj[\"f\"] <= si[\"f\"]) and np.any(sj[\"f\"] < si[\"f\"])\n",
    "               for j, sj in enumerate(sols) if i!=j):\n",
    "            continue\n",
    "        front.append(si)\n",
    "    return front\n",
    "\n",
    "def crowding_distance(front):\n",
    "    N, k = len(front), front[0][\"f\"].size\n",
    "    F = np.array([s[\"f\"] for s in front])\n",
    "    dist = np.zeros(N)\n",
    "    for m in range(k):\n",
    "        idx = np.argsort(F[:,m])\n",
    "        f_min, f_max = F[idx[0],m], F[idx[-1],m]\n",
    "        dist[idx[0]] = dist[idx[-1]] = np.inf\n",
    "        if f_max == f_min: continue\n",
    "        for i in range(1, N-1):\n",
    "            dist[idx[i]] += (F[idx[i+1],m] - F[idx[i-1],m]) / (f_max - f_min)\n",
    "    return dist\n",
    "\n",
    "def pareto_rank_all(solutions):\n",
    "    \"\"\"\n",
    "    Clasifica todas las soluciones en frentes de Pareto.\n",
    "    Devuelve una lista de listas: cada sublista contiene un frente.\n",
    "    \"\"\"\n",
    "    remaining = solutions.copy()\n",
    "    fronts = []\n",
    "    \n",
    "    while remaining:\n",
    "        current_front = []\n",
    "        for i, si in enumerate(remaining):\n",
    "            dominated = False\n",
    "            for j, sj in enumerate(remaining):\n",
    "                if i == j:\n",
    "                    continue\n",
    "                if np.all(sj[\"f\"] <= si[\"f\"]) and np.any(sj[\"f\"] < si[\"f\"]):\n",
    "                    dominated = True\n",
    "                    break\n",
    "            if not dominated:\n",
    "                current_front.append(si)\n",
    "        \n",
    "        fronts.append(current_front)\n",
    "        remaining = [s for s in remaining if all(s is not r for r in current_front)]\n",
    "    \n",
    "    return fronts\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a17da8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CudaGraph' object has no attribute 'nodes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 1) Leer el único grafo bipartito\u001b[39;00m\n\u001b[1;32m      5\u001b[0m gb \u001b[38;5;241m=\u001b[39m ig\u001b[38;5;241m.\u001b[39mGraph\u001b[38;5;241m.\u001b[39mRead_GraphML(FILENAME)\n\u001b[0;32m----> 6\u001b[0m bip_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_bip_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtnodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m bip_metrics\n",
      "Cell \u001b[0;32mIn[19], line 25\u001b[0m, in \u001b[0;36mcompute_bip_metrics\u001b[0;34m(gb, typen)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#x8 = average_local_bipartite_clustering_coefficient(gb, U_type_value=typen)    \u001b[39;00m\n\u001b[1;32m     24\u001b[0m x8 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.25\u001b[39m\n\u001b[0;32m---> 25\u001b[0m x9 \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_avg_path_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m#try:\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m#    x9 = compute_avg_path_length(gb, 100)\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m#except:\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m#    x9 = np.inf\u001b[39;00m\n\u001b[1;32m     30\u001b[0m x11 \u001b[38;5;241m=\u001b[39m compute_power_law_bipartite(gb, typen)\n",
      "Cell \u001b[0;32mIn[19], line 4\u001b[0m, in \u001b[0;36mcompute_avg_path_length\u001b[0;34m(g, k)\u001b[0m\n\u001b[1;32m      2\u001b[0m G \u001b[38;5;241m=\u001b[39m g\u001b[38;5;241m.\u001b[39mto_networkx()\n\u001b[1;32m      3\u001b[0m G \u001b[38;5;241m=\u001b[39m nxcg\u001b[38;5;241m.\u001b[39mfrom_networkx(G)\n\u001b[0;32m----> 4\u001b[0m all_nodes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mG\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnodes\u001b[49m())\n\u001b[1;32m      5\u001b[0m sample_nodes \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39msample(all_nodes, k)\n\u001b[1;32m      6\u001b[0m total_distances \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CudaGraph' object has no attribute 'nodes'"
     ]
    }
   ],
   "source": [
    "# —————————— Flujo principal ——————————\n",
    "tnodes = 0\n",
    "\n",
    "# 1) Leer el único grafo bipartito\n",
    "gb = ig.Graph.Read_GraphML(FILENAME)\n",
    "bip_metrics = compute_bip_metrics(gb, tnodes)\n",
    "bip_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1367c6c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Graph' object has no attribute 'connected_components'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fname \u001b[38;5;129;01min\u001b[39;00m proj_files:\n\u001b[1;32m     15\u001b[0m     gu \u001b[38;5;241m=\u001b[39m ig\u001b[38;5;241m.\u001b[39mGraph\u001b[38;5;241m.\u001b[39mRead_GraphML(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(proj_dir, fname))\n\u001b[0;32m---> 16\u001b[0m     proj_metrics \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_proj_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     sol \u001b[38;5;241m=\u001b[39m evaluate_solution(bip_metrics, proj_metrics, tnodes)\n\u001b[1;32m     18\u001b[0m     sol[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilename\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m fname  \u001b[38;5;66;03m# <- Añadimos esta línea\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[11], line 21\u001b[0m, in \u001b[0;36mcompute_proj_metrics\u001b[0;34m(gu)\u001b[0m\n\u001b[1;32m     19\u001b[0m x4 \u001b[38;5;241m=\u001b[39m gu\u001b[38;5;241m.\u001b[39mvcount()\n\u001b[1;32m     20\u001b[0m x5 \u001b[38;5;241m=\u001b[39m gu\u001b[38;5;241m.\u001b[39mecount()\n\u001b[0;32m---> 21\u001b[0m x6 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mgu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnected_components\u001b[49m())\n\u001b[1;32m     22\u001b[0m x7 \u001b[38;5;241m=\u001b[39m gu\u001b[38;5;241m.\u001b[39mtransitivity_undirected(mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzero\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m x10 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39minf\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Graph' object has no attribute 'connected_components'"
     ]
    }
   ],
   "source": [
    "# 2) Escanear carpeta de proyecciones\n",
    "if tnodes == 0:\n",
    "    proj_dir = \"am/top\"    \n",
    "else:\n",
    "    proj_dir = \"am/bot\"\n",
    "    \n",
    "proj_files = [f for f in os.listdir(proj_dir)\n",
    "              if f.endswith(\".graphml\") and f!=\"bipartito.graphml\"]\n",
    "\n",
    "\n",
    "# 3) Calcular soluciones\n",
    "solutions = []\n",
    "conta_neg = 0\n",
    "for fname in proj_files:\n",
    "    gu = ig.Graph.Read_GraphML(os.path.join(proj_dir, fname))\n",
    "    proj_metrics = compute_proj_metrics(gu)\n",
    "    sol = evaluate_solution(bip_metrics, proj_metrics, tnodes)\n",
    "    sol[\"filename\"] = fname  # <- Añadimos esta línea\n",
    "    solutions.append(sol)\n",
    "    break\n",
    "    #if is_feasible(sol):\n",
    "    #    solutions.append(sol)\n",
    "    \n",
    "print(\"Soluciones factibles:\", len(solutions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f5e985",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fronts = pareto_rank_all(solutions)\n",
    "\n",
    "for rank, front in enumerate(all_fronts, 1):\n",
    "    print(f\"\\nFrente {rank} ({len(front)} soluciones):\")\n",
    "    for sol in front:\n",
    "        print(f\" - {sol['filename']} — f = {sol['f']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e33ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cd = crowding_distance(all_fronts[0])\n",
    "pareto_sorted = [s for _, s in sorted(zip(-cd, all_fronts[0]), key=lambda x: x[0])]\n",
    "print(\"Crowding\", len(pareto_sorted))\n",
    "print(pareto_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdb5f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Asumiendo que ya tienes: all_fronts = pareto_rank_all(solutions)\n",
    "\n",
    "# Preparar datos\n",
    "points = []\n",
    "labels = []\n",
    "\n",
    "for front_idx, front in enumerate(all_fronts):\n",
    "    for sol in front:\n",
    "        points.append(sol[\"f\"])\n",
    "        labels.append(front_idx)  # índice de frente\n",
    "\n",
    "points = np.array(points)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Aplicar t-SNE\n",
    "tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
    "embedding = tsne.fit_transform(points)\n",
    "\n",
    "# Graficar\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter = plt.scatter(embedding[:, 0], embedding[:, 1],\n",
    "                      c=labels, cmap=\"tab10\", s=50, edgecolors='k')\n",
    "\n",
    "plt.title(\"Visualización t-SNE de soluciones por frente de Pareto\")\n",
    "plt.xlabel(\"t-SNE componente 1\")\n",
    "plt.ylabel(\"t-SNE componente 2\")\n",
    "plt.grid(True, linestyle=\"--\", alpha=0.3)\n",
    "legend = plt.legend(*scatter.legend_elements(), title=\"Frente\", loc=\"upper right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b60d307",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
