{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Model - Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import igraph as ig\n",
    "import networkx as nx\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32769 entries, 0 to 32768\n",
      "Data columns (total 10 columns):\n",
      " #   Column            Non-Null Count  Dtype\n",
      "---  ------            --------------  -----\n",
      " 0   ACTION            32769 non-null  int64\n",
      " 1   RESOURCE          32769 non-null  int64\n",
      " 2   MGR_ID            32769 non-null  int64\n",
      " 3   ROLE_ROLLUP_1     32769 non-null  int64\n",
      " 4   ROLE_ROLLUP_2     32769 non-null  int64\n",
      " 5   ROLE_DEPTNAME     32769 non-null  int64\n",
      " 6   ROLE_TITLE        32769 non-null  int64\n",
      " 7   ROLE_FAMILY_DESC  32769 non-null  int64\n",
      " 8   ROLE_FAMILY       32769 non-null  int64\n",
      " 9   ROLE_CODE         32769 non-null  int64\n",
      "dtypes: int64(10)\n",
      "memory usage: 2.5 MB\n",
      "None\n",
      "|U|:  9561\n",
      "|R|:  7518\n",
      "|U| : 9561\n",
      "|L'| : 32769  = |L| : 32769\n",
      "\n",
      "Num positive entries: 30872 94.21%\n",
      "Num negative entries: 1897 5.789%\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# LOAD DATA\n",
    "url_file = \"../00-Data/train.csv\"\n",
    "df_data = pd.read_csv(url_file)\n",
    "print(\"Data loaded!\")\n",
    "print(df_data.info())\n",
    "\n",
    "# User attributes\n",
    "user_attrs = df_data.columns[2:]\n",
    "\n",
    "# Number of users\n",
    "n_users = len(df_data[user_attrs].drop_duplicates())\n",
    "n_rsrcs = len(df_data.RESOURCE.drop_duplicates())\n",
    "print(\"|U|: \", n_users) # Unique users\n",
    "print(\"|R|: \", n_rsrcs) # Unique resources\n",
    "\n",
    "# Create an index for every users\n",
    "user_dict = {}\n",
    "for u_idx, u_attr in enumerate(df_data[user_attrs].drop_duplicates().values):\n",
    "    idx = str(u_idx) + \"101\"\n",
    "    user_dict[int(idx)] = list(u_attr)\n",
    "print(\"|U| :\", len(user_dict))\n",
    "\n",
    "# Create a new column to add in a DF\n",
    "list_usr_idx = []\n",
    "key_list = list(user_dict.keys()) # list out keys and values separately\n",
    "val_list = list(user_dict.values())\n",
    "for log in df_data[user_attrs].values:\n",
    "    key_idx = val_list.index(list(log))\n",
    "    list_usr_idx.append(key_list[key_idx])\n",
    "print(\"|L'| :\", len(list_usr_idx), \" = |L| :\", len(df_data))\n",
    "df_data[\"USERID\"] = list_usr_idx\n",
    "\n",
    "print()\n",
    "df_pos_entries = df_data[df_data.ACTION==1]\n",
    "df_neg_entries = df_data[df_data.ACTION==0]\n",
    "print('Num positive entries:',len(df_pos_entries), \n",
    "    \"{:.4}%\".format((len(df_pos_entries)/len(df_data))*100))\n",
    "print('Num negative entries:',len(df_neg_entries),\n",
    "    \"{:.4}%\".format((len(df_neg_entries)/len(df_data))*100))\n",
    "\n",
    "##### ***** Cross-Validation ***** #####\n",
    "k = 10\n",
    "test_size = 0.2\n",
    "kfold = StratifiedShuffleSplit(n_splits=k, test_size=test_size, random_state=1)\n",
    "\n",
    "data_partition = kfold.split(df_data, df_data.ACTION)\n",
    "data_corpus = [] # Lista donde se almacenan los k fols\n",
    "\n",
    "for train_data, test_data in data_partition:        \n",
    "    X_train, X_test = df_data.iloc[train_data], df_data.iloc[test_data]\n",
    "    data_corpus.append([X_train, X_test])\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Train access request = 26215  %: 80.00\n",
      "# Test access request = 6554  %: 20.00\n",
      "# Total = 32769\n",
      "\n",
      "TASK 1: Done!\n",
      "\n",
      "TASK 2: Done!\n",
      "\n",
      "TASK 3: Drop duplicates access requests\n",
      "\n",
      "# Solicitudes Train (+): 24697  %: 94.21\n",
      "# Solicitudes Train (-): 1518  %: 5.79\n",
      "# Solicitudes Test (+): 6175  %: 94.22\n",
      "# Solicitudes Test (-): 379  %: 5.78\n",
      "# Train Users (+):  8576\n",
      "# Train Resrc (+):  6414\n",
      "# Train Users (-):  830\n",
      "# Train Resrc (-):  950\n",
      "# Test Users (+):  4087\n",
      "# Test Resrc (+):  2748\n",
      "# Test Users (-):  301\n",
      "# Test Resrc (-):  316\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##### ***** Control Variables ***** #####\n",
    "id_kfold = 0\n",
    "task4 = False\n",
    "#########################################\n",
    "\n",
    "df_train_k, df_test_k = data_corpus[id_kfold][0], data_corpus[id_kfold][1]\n",
    "print(\"# Train access request =\", len(df_train_k), \n",
    "      \" %: {:.2f}\".format((len(df_train_k)/(len(df_train_k)+len(df_test_k)))*100))\n",
    "print(\"# Test access request =\", len(df_test_k),\n",
    "      \" %: {:.2f}\".format((len(df_test_k)/(len(df_train_k)+len(df_test_k)))*100))\n",
    "print(\"# Total =\", len(df_train_k)+len(df_test_k))\n",
    "print()\n",
    "\n",
    "##### ***** Task 1: Null and uknwokn values ***** #####\n",
    "print(\"TASK 1: Done!\"); print() # NA\n",
    "\n",
    "\n",
    "##### ***** TASK 2: convert continuous values to categorical values ***** #####\n",
    "print(\"TASK 2: Done!\"); print() # NA \n",
    "\n",
    "##### ***** TASK 3: Drop duplicates access requests ***** #####\n",
    "print(\"TASK 3: Drop duplicates access requests\")\n",
    "df_train_k_pos = df_train_k[df_train_k.ACTION==1]   # Train Pos\n",
    "df_train_k_neg = df_train_k[df_train_k.ACTION==0]   # Train Neg\n",
    "df_test_k_pos = df_test_k[df_test_k.ACTION==1]      # Test Pos\n",
    "df_test_k_neg = df_test_k[df_test_k.ACTION==0]      # Test Neg\n",
    "df_train_k_pos = df_train_k_pos[df_train_k_pos.columns[1:]].drop_duplicates()\n",
    "df_train_k_neg = df_train_k_neg[df_train_k_neg.columns[1:]].drop_duplicates()\n",
    "df_test_k_pos = df_test_k_pos[df_test_k_pos.columns[1:]].drop_duplicates()\n",
    "df_test_k_neg = df_test_k_neg[df_test_k_neg.columns[1:]].drop_duplicates()\n",
    "print()\n",
    "\n",
    "print(\"# Solicitudes Train (+):\", len(df_train_k_pos), \" %: {:.2f}\".format((len(df_train_k_pos)/len(df_train_k))*100))\n",
    "print(\"# Solicitudes Train (-):\", len(df_train_k_neg), \" %: {:.2f}\".format((len(df_train_k_neg)/len(df_train_k))*100))\n",
    "print(\"# Solicitudes Test (+):\", len(df_test_k_pos), \" %: {:.2f}\".format((len(df_test_k_pos)/len(df_test_k))*100))\n",
    "print(\"# Solicitudes Test (-):\", len(df_test_k_neg), \" %: {:.2f}\".format((len(df_test_k_neg)/len(df_test_k))*100))\n",
    "print(\"# Train Users (+): \", len(df_train_k_pos.USERID.drop_duplicates()))\n",
    "print(\"# Train Resrc (+): \", len(df_train_k_pos.RESOURCE.drop_duplicates()))\n",
    "print(\"# Train Users (-): \", len(df_train_k_neg.USERID.drop_duplicates()))\n",
    "print(\"# Train Resrc (-): \", len(df_train_k_neg.RESOURCE.drop_duplicates()))\n",
    "print(\"# Test Users (+): \", len(df_test_k_pos.USERID.drop_duplicates()))\n",
    "print(\"# Test Resrc (+): \", len(df_test_k_pos.RESOURCE.drop_duplicates()))\n",
    "print(\"# Test Users (-): \", len(df_test_k_neg.USERID.drop_duplicates()))\n",
    "print(\"# Test Resrc (-): \", len(df_test_k_neg.RESOURCE.drop_duplicates())); print()\n",
    "\n",
    "if task4:\n",
    "    # Filter resources\n",
    "      n1 = 0\n",
    "      n2 = 149\n",
    "      top_list = df_train_k_pos.RESOURCE.value_counts()[:len(df_train_k_pos.RESOURCE.drop_duplicates())].index.tolist()\n",
    "      # Filter the interval between n1 and n2\n",
    "      top_list = top_list[n1:n2+1]\n",
    "      print('#Filtered resources:', len(top_list))\n",
    "      boolean_series = df_train_k_pos.RESOURCE.isin(top_list)\n",
    "      df_train_k_pos = df_train_k_pos[boolean_series]\n",
    "      bolean_series = df_train_k_neg.RESOURCE.isin(top_list)\n",
    "      df_train_k_neg = df_train_k_neg[bolean_series]\n",
    "      print(\"Done!\")\n",
    "      "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_network_model(data, usr_id_name, res_id_name, file_path=None):\n",
    "    \"\"\"\n",
    "    Builds the Access Requests Bipartite Network from Access log.\n",
    "\n",
    "    Args:\n",
    "        data (pandas dataframe): The Access Log.\n",
    "        usr_id_name (str): The name of the ID users column in the Access Log\n",
    "        res_id_name (str): The name of the ID resources column in the Access Log\n",
    "    \n",
    "    Returns:\n",
    "        Graph (iGraph): The Access Requests Bipartite Network.\n",
    "\n",
    "    Raises:\n",
    "        TypeError: If a network is not Bipartite.\n",
    "    \"\"\"\n",
    "    \n",
    "    list_of_edges = []\n",
    "    bi_network = nx.Graph() # NetworkX Graph object\n",
    "\n",
    "    for usr_idx, rsr_idx in data[[usr_id_name, res_id_name]].values:\n",
    "        list_of_edges.append((int(usr_idx), int(rsr_idx))) # Tuple of edges\n",
    "    bi_network.add_edges_from(list_of_edges) # Build Network with edges\n",
    "\n",
    "    # Change networkX object to iGraph object\n",
    "    bi_network = ig.Graph.from_networkx(bi_network)\n",
    "    bi_network.vs['name'] = bi_network.vs[\"_nx_name\"] # Clean name column\n",
    "    del bi_network.vs[\"_nx_name\"] # Remove uncleaned name column\n",
    "\n",
    "    if not bi_network.is_bipartite():\n",
    "        raise TypeError(\"The ARBN is not bipartite\")\n",
    "\n",
    "    ### Add type of node (user or resource)\n",
    "    list_of_resources_in_data = list(data[res_id_name])\n",
    "    list_node_type = []\n",
    "    for node in bi_network.vs():\n",
    "        if node['name'] in list_of_resources_in_data:\n",
    "            list_node_type.append(1) # A resource\n",
    "        else:\n",
    "            list_node_type.append(0) # An user\n",
    "    bi_network.vs[\"typen\"] = list_node_type\n",
    "    ### End node type\n",
    "\n",
    "    if not file_path == None: # Create a file\n",
    "        ig.write(bi_network, file_path)\n",
    "\n",
    "    print(\"ARBN builded!\")\n",
    "    print(bi_network.summary())\n",
    "    print(\"|U-Nodes| =\", len(bi_network.vs.select(typen=0)))\n",
    "    print(\"|R-Nodes| =\", len(bi_network.vs.select(typen=1)))\n",
    "\n",
    "    return bi_network\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The ARBN is not bipartite",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26674/1486280971.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbip_network\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_network_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train_k_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'USERID'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'RESOURCE'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_26674/3114919643.py\u001b[0m in \u001b[0;36mbuild_network_model\u001b[0;34m(data, usr_id_name, res_id_name, file_path)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbi_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bipartite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The ARBN is not bipartite\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;31m### Add type of node (user or resource)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: The ARBN is not bipartite"
     ]
    }
   ],
   "source": [
    "bip_network = build_network_model(df_train_k_pos, 'USERID', 'RESOURCE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IGRAPH UN-- 5586 9501 -- \\n+ attr: name (v), typen (v)'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bip_network.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "deec884ae07beaa7e970d39d84b9343805b80aeba4e343861fb4097b62dc7004"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
